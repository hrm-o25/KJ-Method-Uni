{"pageProps":{"result":{"clusters":[{"cluster":"University Research and Industry Collaboration","cluster_id":"4","takeaways":"The comments highlight challenges in managing research from seed discovery to implementation, with concerns about industry-academia collaborations, patent monopolies, funding sources, and administrative burdens on researchers. Issues raised include the integration of university startups into pharmaceutical companies, the need for independent research funding for universities, and the prioritization of practical learning and industry-funded research. Disputes over rights in collaborative research and the limited dissemination of emerging technologies for practical applications are also noted. The comments underscore the complex balance required in research, management, and education roles within the university sector.","arguments":[{"arg_id":"A0_0","argument":"There is no consistent system in place to manage from seed discovery to utilization of results.","comment_id":"0","x":-2.828389,"y":6.912325,"p":0.9856495965877732},{"arg_id":"A1_0","argument":"Pharmaceutical companies acquiring university startups and integrating them into their research departments.","comment_id":"1","x":-3.2926784,"y":7.871377,"p":0},{"arg_id":"A3_0","argument":"Having own research facilities is possible for companies like GAFA, NTT, and Nomura Research Institute.","comment_id":"3","x":-3.3314388,"y":7.725908,"p":0},{"arg_id":"A5_0","argument":"Companies should not be able to monopolize research results like patents.","comment_id":"5","x":-3.4276319,"y":7.1852303,"p":0.6767886181581774},{"arg_id":"A5_1","argument":"If a company monopolizes research results, they should bear the obligation to pay substantial implementation fees.","comment_id":"5","x":-3.4780228,"y":7.06315,"p":1},{"arg_id":"A7_0","argument":"Universities, including national ones, need to secure research funding independently.","comment_id":"7","x":-3.1845741,"y":7.1039824,"p":1},{"arg_id":"A7_1","argument":"Without corporate-sponsored courses, it is challenging for research to continue.","comment_id":"7","x":-2.9024167,"y":6.8632965,"p":1},{"arg_id":"A7_2","argument":"Research on topics that attract funding from the private sector tends to be prioritized.","comment_id":"7","x":-2.9977083,"y":7.435163,"p":1},{"arg_id":"A7_3","argument":"There is a bias towards practical learning.","comment_id":"7","x":-2.3104239,"y":7.6489363,"p":1},{"arg_id":"A9_0","argument":"Collaborative research can lead to disputes over rights.","comment_id":"9","x":-3.4698014,"y":7.0511575,"p":1},{"arg_id":"A9_1","argument":"Example: Ono Pharmaceutical vs. Honjo Tasuku - Opdivo lawsuit.","comment_id":"9","x":-3.6587753,"y":7.4311337,"p":0},{"arg_id":"A10_0","argument":"Industry-academia collaboration research funding does not contribute to university operating expenses.","comment_id":"10","x":-3.2537599,"y":6.9102035,"p":0.3727594685341354},{"arg_id":"A11_0","argument":"Information dissemination on emerging technologies that could lead to practical applications is limited, making it difficult for companies to catch up.","comment_id":"11","x":-2.9651043,"y":7.193739,"p":1},{"arg_id":"A13_0","argument":"The rules and management regarding joint research and commissioned research, such as trade secrets and profit rebellion, are insufficient.","comment_id":"13","x":-3.5015945,"y":6.9709954,"p":1},{"arg_id":"A40_0","argument":"Government distributing subsidies to drive the university sector can lead to time-consuming administrative tasks for researchers and educators","comment_id":"40","x":-2.730051,"y":6.662496,"p":1},{"arg_id":"A40_1","argument":"Young researchers may experience exhaustion due to the administrative burden caused by grant applications.","comment_id":"40","x":-2.5135596,"y":6.598924,"p":0},{"arg_id":"A43_1","argument":"Research","comment_id":"43","x":-2.8477023,"y":7.639896,"p":0},{"arg_id":"A80_0","argument":"Manufacturers bear risks from mass production to sales, while research appears to have less risk.","comment_id":"80","x":-3.0989268,"y":7.557349,"p":0},{"arg_id":"A95_0","argument":"Balancing research, management, and education roles is a challenging task.","comment_id":"95","x":-2.5035179,"y":7.0969505,"p":0}]},{"cluster":"Evolution of Social Engagement in Universities","cluster_id":"3","takeaways":"Participants highlighted the importance of forming an economic community and the role of relationships in defining oneself. They referenced Sartre's quote \"Hell is other people\" to underscore the significance of interpersonal connections. The concept of \"Comoning\" was discussed as a relationship-oriented and practical approach. The discussion also touched on DAOs as ecosystems coordinating human actions around protocols. Emphasizing the need for communication and negotiation in forming commons, the dialogue stressed the inadequacy of laws alone in societal contexts and the importance of collaborative spaces for exchanging diverse perspectives on public issues.","arguments":[{"arg_id":"A2_0","argument":"経済的なコミュニティを形成する","comment_id":"2","x":8.288223,"y":6.566899,"p":1},{"arg_id":"A15_0","argument":"人間は社会性の生き物であり、他者からの眼差しで自己を定義し、不自由を感じることがある。","comment_id":"15","x":8.12521,"y":6.7890935,"p":1},{"arg_id":"A15_1","argument":"サルトルの言葉「地獄とは他人のことだ」を参考にすると、他者との関係が人間にとって重要であることが示唆される。","comment_id":"15","x":7.9496393,"y":6.427051,"p":1},{"arg_id":"A23_0","argument":"コモニング: Participating freely, accepting and managing it. Relationship-oriented and practical.","comment_id":"23","x":8.437051,"y":6.261414,"p":1},{"arg_id":"A24_0","argument":"DAOはプロトコルを中心に人々の行動を調整するエコシステムであり、PJに参加してトークンを得ることができる。","comment_id":"24","x":7.789422,"y":6.6026525,"p":1},{"arg_id":"A25_1","argument":"参加者の綿密なコミュニケーションや相互理解は不要","comment_id":"25","x":8.246967,"y":6.016727,"p":1},{"arg_id":"A27_0","argument":"人々がコモンズとして考え、行動し、交渉することで形成される。","comment_id":"27","x":8.360039,"y":6.5027637,"p":1},{"arg_id":"A31_1","argument":"法律だけでは社会で通用しない","comment_id":"31","x":8.06518,"y":6.734221,"p":1},{"arg_id":"A49_1","argument":"単一性・私的","comment_id":"49","x":7.947352,"y":6.195264,"p":1},{"arg_id":"A53_0","argument":"共同行為における言葉の重要性","comment_id":"53","x":8.183587,"y":6.118693,"p":1},{"arg_id":"A53_1","argument":"複数性と公共性の関連性","comment_id":"53","x":8.007822,"y":6.0374947,"p":1},{"arg_id":"A58_0","argument":"共創空間が必要で、公共の問題について話し合い、複数の意見を交換することが重要。","comment_id":"58","x":7.852641,"y":6.0038204,"p":1}]},{"cluster":"Evolution of University Role","cluster_id":"6","takeaways":"Universities serve as common spaces for collaboration, knowledge dissemination, and societal integration, with a focus on liberal arts, research, and education. They are evolving to meet the demands of a knowledge-based society, emphasizing cooperation between students and teachers. The historical context of universities transitioning from medieval knowledge centers to modern multifunctional institutions is highlighted, showcasing their role in national culture and modernization efforts. The importance of universities in promoting arts and sciences integration, facilitating learning through seminars and laboratories, and contributing to societal expectations and national interests is underscored.","arguments":[{"arg_id":"A4_0","argument":"Companies and investors are gathering near universities.","comment_id":"4","x":-2.5982552,"y":8.463408,"p":0.5437681125321103},{"arg_id":"A26_0","argument":"Universities as common spaces: Spaces shaped by collective actions, negotiations, and interactions, not owned by anyone.","comment_id":"26","x":-2.091876,"y":9.042316,"p":0.7396983776406113},{"arg_id":"A29_0","argument":"Libraries and cafeterias are open to the general public.","comment_id":"29","x":-2.1312697,"y":8.9367285,"p":0.7396983776406113},{"arg_id":"A37_0","argument":"Students and teachers collaborate, with students focusing on liberal arts and research, and teachers on research and education. Administrative staff work on fundraising and university branding.","comment_id":"37","x":-1.9279037,"y":9.406391,"p":1},{"arg_id":"A45_0","argument":"Local universities are supplying new young people (workers) to their respective regions.","comment_id":"45","x":-2.498741,"y":8.536711,"p":0.5331860176413642},{"arg_id":"A55_0","argument":"Universities should promote the integration of arts and sciences.","comment_id":"55","x":-1.9637581,"y":9.387957,"p":1},{"arg_id":"A63_0","argument":"From the 16th to the 18th century, Gutenberg's printing press led to the widespread availability of books, shifting the production of cutting-edge knowledge from university researchers to independent writers and publishers.","comment_id":"63","x":-2.9820724,"y":8.770924,"p":1},{"arg_id":"A64_0","argument":"The dramatic increase in book production leads to the mass duplication and dissemination of knowledge, marking the end of the era of wandering in search of knowledge and the loss of the foundation of the medieval university system, ushering in an era of comparing and cross-referencing numerous books.","comment_id":"64","x":-2.8720834,"y":8.809019,"p":1},{"arg_id":"A65_0","argument":"Before the advancement of publishing technology, seeking knowledge involved meeting knowledgeable individuals or reading manuscripts stored in places like monasteries.","comment_id":"65","x":-2.9091303,"y":8.622719,"p":1},{"arg_id":"A66_0","argument":"Modern universities: Cooperation between students and teachers ('universitas' free movement) vs. urban ruling class.","comment_id":"66","x":-2.3187494,"y":9.204336,"p":0.7396983776406113},{"arg_id":"A67_0","argument":"Using city facilities like churches and squares for classes can lead to the creation of new universities in cities as people move from city to city.","comment_id":"67","x":-2.3730097,"y":8.870037,"p":0.6254305802616119},{"arg_id":"A68_0","argument":"Minerva University was established in the United States in 2012 without a traditional campus.","comment_id":"68","x":-2.0209923,"y":8.572135,"p":0},{"arg_id":"A69_0","argument":"Transition to a knowledge-based society has increased societal expectations on university education and research functions since the late 1990s.","comment_id":"69","x":-2.736478,"y":8.1511965,"p":0},{"arg_id":"A71_1","argument":"Universities are not just for the elite","comment_id":"71","x":-2.1301692,"y":8.564296,"p":0},{"arg_id":"A72_0","argument":"Universities are the foundation for the revitalization of national culture.","comment_id":"72","x":-2.497269,"y":9.353623,"p":0.8861426497142796},{"arg_id":"A74_0","argument":"Establishing seminars for humanities and laboratories for sciences to facilitate learning for both students and teachers.","comment_id":"74","x":-1.8592577,"y":9.392657,"p":1},{"arg_id":"A75_0","argument":"The purpose of establishing universities in Japan is to strengthen the national power and serve as a tool for modernization.","comment_id":"75","x":-2.4758203,"y":9.588989,"p":1},{"arg_id":"A75_1","argument":"Universities in Japan are seen as elite training schools that directly contribute to the national interest.","comment_id":"75","x":-2.6814024,"y":9.60517,"p":0.8458134675916275},{"arg_id":"A76_0","argument":"Ortega in the 1930s Spain highlighted the mission of universities: 1. Liberal education, 2. Professional training, 3. Science.","comment_id":"76","x":-2.220703,"y":9.732319,"p":0.6206799926354438},{"arg_id":"A77_0","argument":"Clark Kerr's 'The Uses of the University' emphasizes the multifunctionality of modern universities in education, research, and service.","comment_id":"77","x":-2.460387,"y":9.502235,"p":1}]},{"cluster":"Evolution of University Experience","cluster_id":"0","takeaways":"International student connections with companies, campus appeal, meaningful campus life, post-graduation prospects, and the importance of diverse courses and experiences were highlighted. The role of professors as role models, the value of real-world professional experience in teaching, and the impact of university choice on future employment opportunities were also emphasized. Additionally, the significance of cross-cultural knowledge exchange, the impact of personal opinions in coursework, and the influence of diverse academic experiences on career decisions were noted.","arguments":[{"arg_id":"A6_0","argument":"Accepting international students can create connections with overseas companies.","comment_id":"6","x":-1.2546226,"y":8.334126,"p":1},{"arg_id":"A34_0","argument":"A good location and a beautiful campus can increase the desirability of a university.","comment_id":"34","x":-1.6500757,"y":8.825044,"p":0},{"arg_id":"A34_1","argument":"Having a meaningful campus life experience is important for students.","comment_id":"34","x":-1.069932,"y":8.903591,"p":0.7994468046127283},{"arg_id":"A35_0","argument":"Consider the hierarchy of positions after graduation when choosing a good university.","comment_id":"35","x":-1.529406,"y":8.127986,"p":0.7624463763616282},{"arg_id":"A38_0","argument":"University professors should be role models by being intellectually cool.","comment_id":"38","x":-1.5116817,"y":8.43511,"p":1},{"arg_id":"A39_0","argument":"Researchers are attractive for their self-centeredness and hobby-like approach to their profession.","comment_id":"39","x":-2.1445205,"y":7.8579464,"p":1},{"arg_id":"A42_0","argument":"Invite professionals with real-world experience to become professors.","comment_id":"42","x":-1.2828805,"y":8.815182,"p":0.594645340111194},{"arg_id":"A43_2","argument":"Contribution to society (local, economic, international)","comment_id":"43","x":-1.4465554,"y":8.461722,"p":1},{"arg_id":"A60_0","argument":"Sharing and exchanging knowledge among people from diverse countries and cultures.","comment_id":"60","x":-0.9342565,"y":8.355428,"p":0.9657704669725616},{"arg_id":"A68_1","argument":"Students learn while traveling around the world, combining academic curriculum (online) with cross-cultural experiences (residences in various countries).","comment_id":"68","x":-1.0770729,"y":8.545807,"p":0.9295160481057488},{"arg_id":"A70_0","argument":"Employment opportunities are often determined by the university one graduates from, rather than just having a bachelor's degree.","comment_id":"70","x":-1.6357151,"y":7.8458934,"p":0},{"arg_id":"A90_0","argument":"The student found history and religious studies courses to be the most memorable during their university days.","comment_id":"90","x":-0.91718215,"y":9.104213,"p":1},{"arg_id":"A90_1","argument":"The diversity and uniqueness of these courses compared to engineering made them stand out.","comment_id":"90","x":-0.8965628,"y":9.304739,"p":1},{"arg_id":"A90_2","argument":"The student appreciated the opportunity to include personal opinions in reports for these courses, unlike in engineering reports.","comment_id":"90","x":-0.7070506,"y":9.180358,"p":0.9019299444582686},{"arg_id":"A90_3","argument":"The student found a romantic aspect in theology, which influenced their career change driven by a search for romance in life.","comment_id":"90","x":-1.0603838,"y":9.191755,"p":1},{"arg_id":"A92_0","argument":"General education courses where students from various departments interact are most enjoyable in the first year.","comment_id":"92","x":-0.59131265,"y":9.057911,"p":0.7777526092361459},{"arg_id":"A100_0","argument":"Studying abroad during university is common at certain universities","comment_id":"100","x":-1.3727236,"y":8.31664,"p":1},{"arg_id":"A100_1","argument":"Studying abroad provides opportunities to experience different cultures and products","comment_id":"100","x":-1.0267992,"y":8.303696,"p":1},{"arg_id":"A101_0","argument":"Entering a research department allows for close relationships with professors, seniors, and juniors.","comment_id":"101","x":-0.78608066,"y":8.886904,"p":0.7777526092361459},{"arg_id":"A101_1","argument":"Having peers who pursue the same field of study can be beneficial.","comment_id":"101","x":-0.5319956,"y":8.613329,"p":0}]},{"cluster":"Evolution of University Role and Trends","cluster_id":"2","takeaways":"The comments touch on the importance of establishing university startups, considering mergers of private universities, the evolution of the university system through historical events, the integration of research and education in the Humboldtian university concept, and the trend of students choosing majors based on future job prospects. Additionally, there is a mention of PBL education, early internships, and the balance between enjoying campus life and focusing on future employment.","arguments":[{"arg_id":"A8_0","argument":"大学の近くに大学発ベンチャーを設立することが重要である。","comment_id":"8","x":6.9342837,"y":7.568988,"p":1},{"arg_id":"A21_0","argument":"慶應義塾長 suggests increasing university tuition fees.","comment_id":"21","x":6.427344,"y":6.912812,"p":1},{"arg_id":"A47_0","argument":"地方私立大学の統合や統廃合について検討が必要","comment_id":"47","x":6.98064,"y":7.0201783,"p":1},{"arg_id":"A54_0","argument":"大学は、生活の心配をせずにその問いを持つことができ、果ての果てまで考え、対話するところ。","comment_id":"54","x":7.014198,"y":7.501511,"p":1},{"arg_id":"A57_0","argument":"学問から離れて、好奇心に従って興味のあることを学ぶことが重要である。","comment_id":"57","x":6.683091,"y":7.398156,"p":1},{"arg_id":"A61_0","argument":"大学の数が増加し、知の形骸化が進んだ","comment_id":"61","x":6.6369586,"y":7.1722093,"p":1},{"arg_id":"A61_1","argument":"宗教改革や国家形成により大学システムの機能不全が露呈した","comment_id":"61","x":6.863622,"y":6.902134,"p":1},{"arg_id":"A62_0","argument":"科学革命において、データの比較照合による仮説検証が重要であった。","comment_id":"62","x":7.2706466,"y":7.0547743,"p":1},{"arg_id":"A62_1","argument":"宗教改革では、印刷技術が教会批判に活用された。","comment_id":"62","x":7.2059417,"y":6.66676,"p":0.8834204876461955},{"arg_id":"A73_0","argument":"「フンボルト的大学観」において、研究と教育を一体として結合させる。","comment_id":"73","x":6.740609,"y":6.9448795,"p":1},{"arg_id":"A73_1","argument":"大学人を第一義的に研究者と規定し、研究成果の披瀝が最高の教育であるとする考え方。","comment_id":"73","x":6.93289,"y":7.1765738,"p":1},{"arg_id":"A78_0","argument":"PBL型教育","comment_id":"78","x":6.838724,"y":6.8761024,"p":1},{"arg_id":"A81_0","argument":"焦っていたため、大学2年生からインターンを始めた。","comment_id":"81","x":6.5796156,"y":7.7092357,"p":1},{"arg_id":"A86_0","argument":"同級生は恋愛や推しのアイドル、MBTIについて話している。","comment_id":"86","x":6.5122786,"y":7.6510954,"p":1},{"arg_id":"A89_0","argument":"学生は大学の学部を将来の就職に関連して選ぶ傾向がある。","comment_id":"89","x":6.3108487,"y":7.4447994,"p":1},{"arg_id":"A89_1","argument":"一部の学部（例：哲学）は就職との関連性が低いとの認識がある。","comment_id":"89","x":6.4361653,"y":7.4796724,"p":1},{"arg_id":"A91_0","argument":"大学生活を楽しむ余白が大切で、就職先よりもキャンパスライフを重視する考え方がある。","comment_id":"91","x":6.7053323,"y":7.693584,"p":1},{"arg_id":"A96_0","argument":"岡村さんは大学を辞めて民間の研究所に行った","comment_id":"96","x":6.6823506,"y":7.333092,"p":1}]},{"cluster":"Changing Role of Universities","cluster_id":"5","takeaways":"The comments touch on the complexities of technical guidance and research contracts, the importance of abiding by rules autonomously, the limitations of laws in addressing demand-specific solutions, the value of acquiring up-to-date knowledge for societal contributions, the necessity of balancing work to sustain life, the pressure on professionals to deliver results within limited timeframes, and the need to consider new admission criteria. Additionally, they highlight the pragmatic nature of actions driven by resume-building, the sense of financial and emotional scarcity, the urgency felt to avoid complacency, the tendency to prioritize high-paying companies as professionals, and the potential for research-focused efforts to significantly increase research budgets.","arguments":[{"arg_id":"A12_0","argument":"技術指導・共同研究契約の手続きが煩雑","comment_id":"12","x":7.6874666,"y":7.252544,"p":1},{"arg_id":"A25_0","argument":"人間の直接的な介入なしに、定められたルールに基づいて行動。","comment_id":"25","x":8.234308,"y":6.924378,"p":1},{"arg_id":"A31_0","argument":"法律は所有権を決めるが、需要に応じた解決策を提供できない","comment_id":"31","x":8.044551,"y":7.0477734,"p":1},{"arg_id":"A48_0","argument":"最新の知識を身につけて社会に貢献する","comment_id":"48","x":7.6065645,"y":6.7127647,"p":0.8834204876461955},{"arg_id":"A49_0","argument":"労働：生命を維持するために実施","comment_id":"49","x":8.383802,"y":7.1053977,"p":1},{"arg_id":"A50_0","argument":"社会人は「時間当たり採算」","comment_id":"50","x":8.392169,"y":7.182204,"p":1},{"arg_id":"A51_0","argument":"成果を出すためには限られた時間が求められる。","comment_id":"51","x":8.041564,"y":7.543938,"p":1},{"arg_id":"A79_0","argument":"新しい入試基準の必要性について考えるべきかもしれない。","comment_id":"79","x":7.365025,"y":7.6874895,"p":0.7974227338122283},{"arg_id":"A81_1","argument":"行動が打算的で、履歴書に書くためだった。","comment_id":"81","x":7.814489,"y":7.6913476,"p":1},{"arg_id":"A81_2","argument":"心が貧しく、財布も貧しかった。","comment_id":"81","x":7.921467,"y":7.5211587,"p":1},{"arg_id":"A81_3","argument":"漠然とした社会にお金がないという危機感を抱いていた。","comment_id":"81","x":8.108101,"y":7.45902,"p":1},{"arg_id":"A81_4","argument":"切り詰めなければ、のんびりしていてはいけないと感じていた。","comment_id":"81","x":8.041492,"y":7.872136,"p":1},{"arg_id":"A91_1","argument":"社会人になると高給料の会社を重視する傾向がある。","comment_id":"91","x":8.184433,"y":7.260231,"p":1},{"arg_id":"A96_1","argument":"研究だけに集中することでリサーチ予算が10倍になった","comment_id":"96","x":7.5512724,"y":7.220327,"p":1}]},{"cluster":"Challenges in Higher Education","cluster_id":"7","takeaways":"The comments touch on various aspects of higher education, highlighting disparities in cultural and lifestyle differences, financial challenges, pressure from academic scholarships, and the impact of online interactions on social connections. Concerns about the practicality of higher education for the impoverished, challenges in financial support transparency, and the shift towards online learning during the pandemic are also discussed. The need for a balance between academic performance and practical skills, as well as the impact of societal expectations on educational choices, is evident throughout the comments.","arguments":[{"arg_id":"A14_0","argument":"Entering prestigious universities based on academic performance may not bridge the gap in cultural and lifestyle differences, leading to disparities in various aspects of life.","comment_id":"14","x":-1.3964623,"y":6.7310195,"p":1},{"arg_id":"A14_1","argument":"Despite academic achievements, individuals may still face challenges in social interactions, career choices, marriage expectations, and appreciation for the arts, reflecting the influence of upbringing and societal expectations.","comment_id":"14","x":-1.0326247,"y":6.7113667,"p":0.7369663194817698},{"arg_id":"A16_0","argument":"Many foreign graduate schools pay stipends to their students instead of charging tuition fees.","comment_id":"16","x":-2.0179107,"y":7.5837736,"p":1},{"arg_id":"A17_0","argument":"Financial support in universities and graduate schools is opaque, leading students to spend significant time on part-time jobs.","comment_id":"17","x":-2.0994964,"y":6.9473324,"p":0.9681778839996724},{"arg_id":"A17_1","argument":"The curriculum does not cater to students who have to spend a considerable amount of time on part-time jobs due to lack of transparency in financial support.","comment_id":"17","x":-2.2358248,"y":6.9185996,"p":1},{"arg_id":"A18_1","argument":"Children of college graduates are more likely to pursue higher education due to understanding the benefits of a degree, engaging in extracurricular activities, and lower financial barriers.","comment_id":"18","x":-1.1240512,"y":7.231356,"p":0.629448515961128},{"arg_id":"A20_0","argument":"Scholarships tied to academic performance create constant pressure to maintain high grades.","comment_id":"20","x":-1.6648499,"y":6.7396703,"p":0.9303690061841368},{"arg_id":"A32_0","argument":"Is higher education unnecessary for the impoverished? - Even if intelligence grows, without practical positions or assets, dissatisfaction accumulates, increasing the causes threatening 'social peace.'","comment_id":"32","x":-0.98448974,"y":6.7836237,"p":0},{"arg_id":"A33_0","argument":"Online connections can be convenient and efficient, but they tend to gather people with similar opinions or backgrounds.","comment_id":"33","x":-1.1576487,"y":6.0007544,"p":0.4304111386963544},{"arg_id":"A36_0","argument":"There are individual differences in how labor hours are counted.","comment_id":"36","x":-2.1855133,"y":6.8319674,"p":1},{"arg_id":"A69_1","argument":"However, challenges such as the massification of university education due to a rapid decline in the population of 18-year-olds and the diversification of secondary education pose significant obstacles to ensuring the quality of higher education.","comment_id":"69","x":-1.5507078,"y":7.074227,"p":0.7596410180299571},{"arg_id":"A71_0","argument":"60% of the 18-year-old population goes to universities or junior colleges","comment_id":"71","x":-1.4752473,"y":7.4534082,"p":0},{"arg_id":"A82_0","argument":"Scholarships with direct payments to parents can sometimes be misused, leading students to work multiple jobs.","comment_id":"82","x":-2.0989895,"y":6.768668,"p":0.7798029722434341},{"arg_id":"A83_0","argument":"Students who want to attend national universities fear not being able to take a gap year. They feel pressured and are becoming more focused on physical activities rather than academics, as they can only see whether they will pass the exams or not.","comment_id":"83","x":-1.4453843,"y":6.9271235,"p":1},{"arg_id":"A87_0","argument":"Under COVID-19, online interactions with like-minded individuals can be more active, but may lead to one-sided arguments.","comment_id":"87","x":-1.2516896,"y":5.7177577,"p":1},{"arg_id":"A87_1","argument":"Difficulty in forming close relationships with professors and classmates due to lack of in-person interactions.","comment_id":"87","x":-1.4660851,"y":5.99009,"p":0.491821015410253},{"arg_id":"A88_0","argument":"Online seminars during the pandemic allowed for more open discussions and increased psychological safety for participants.","comment_id":"88","x":-1.3610262,"y":5.751193,"p":1},{"arg_id":"A88_1","argument":"However, online communication may lead to challenges in maintaining a sense of connection and attentiveness during discussions.","comment_id":"88","x":-1.3156115,"y":5.8290625,"p":1},{"arg_id":"A99_0","argument":"Night worker's friend's story: They wanted to try going to university. They still think philosophy and religious studies are interesting. They can afford it financially, but they find it uncomfortable to live the campus life with 18-year-old students during the day.","comment_id":"99","x":-1.3360648,"y":7.612986,"p":0}]},{"cluster":"Evolution of Educational Approaches","cluster_id":"1","takeaways":"The comments touch on the influence of parental education on children's academic success, the importance of respect and support in education, the shift of power in Web3 technology, the value of diverse engagement methods, and the benefits of interdisciplinary expertise. They also highlight the significance of self-reflection, continuous learning, and the inseparable connection between learning and personal growth. Additionally, the comments suggest the potential for unconventional activities like ikebana to provide relief and purpose, and raise the question of whether pursuing personal interests in adulthood can enhance happiness.","arguments":[{"arg_id":"A18_0","argument":"Parental education level influences children's educational attainment","comment_id":"18","x":-0.55246866,"y":6.978402,"p":1},{"arg_id":"A19_0","argument":"Respect from the surroundings, especially family, is necessary to continue efforts, and without luck, one cannot advance in education.","comment_id":"19","x":-0.72387344,"y":7.1352515,"p":1},{"arg_id":"A22_0","argument":"Expanding the margins of diverse ways of engagement.","comment_id":"22","x":-0.3105663,"y":8.280998,"p":0},{"arg_id":"A28_0","argument":"Web3 (self-regulating decentralized) shifts power from users to stakeholders.","comment_id":"28","x":0.2649405,"y":8.344599,"p":1},{"arg_id":"A38_1","argument":"Using privileged time freedom with a different value system from societal norms.","comment_id":"38","x":0.02751662,"y":7.982992,"p":0.6077118509248265},{"arg_id":"A38_2","argument":"Showing a creative perspective equals the coolness of erudition.","comment_id":"38","x":-0.897307,"y":7.9430532,"p":0.5323405898905247},{"arg_id":"A43_0","argument":"Education","comment_id":"43","x":-0.80267364,"y":7.382029,"p":1},{"arg_id":"A44_0","argument":"Unlocking 'common sense'. Freeing women from the conditioning that they cannot participate unconsciously in decision-making.","comment_id":"44","x":0.14687192,"y":8.109717,"p":1},{"arg_id":"A46_0","argument":"Allowing students to explore without setting specific goals.","comment_id":"46","x":-0.20658584,"y":8.7845125,"p":0.599995234771552},{"arg_id":"A52_0","argument":"Recurrent education","comment_id":"52","x":-0.62017894,"y":7.375987,"p":0.988305868948158},{"arg_id":"A55_1","argument":"Having expertise in multiple fields can be beneficial for each respective field.","comment_id":"55","x":-0.6811869,"y":8.479901,"p":0.8149882322593505},{"arg_id":"A56_0","argument":"Regardless of the field of expertise, it all leads back to reflecting on one's own existence.","comment_id":"56","x":-0.73821294,"y":7.889702,"p":1},{"arg_id":"A59_0","argument":"Regardless of the specialization, it all leads to reflecting on one's own existence.","comment_id":"59","x":-0.6111433,"y":7.810878,"p":1},{"arg_id":"A65_1","argument":"The concepts of 'learning' and 'travel' are inseparable.","comment_id":"65","x":-0.54522467,"y":7.88101,"p":0.8686092244625944},{"arg_id":"A87_2","argument":"Lower dependency on specific individuals or locations.","comment_id":"87","x":0.106584534,"y":8.478085,"p":0.7094239824160266},{"arg_id":"A97_0","argument":"Starting ikebana (Japanese flower arrangement) after beginning work helped me not feel completely exhausted from raising two children as a single mother. It was a relief from feeling like I only had children when coming home from work. Ikebana may not be useful, but it saved me from feeling 'useless'.","comment_id":"97","x":-0.21995872,"y":6.8388853,"p":0.7184078227868275},{"arg_id":"A97_1","argument":"Could having a place to learn what you want to learn (culture) as an adult increase happiness?","comment_id":"97","x":-0.40744364,"y":6.961262,"p":1}]}],"comments":{"0":{"comment":"シーズの発掘から成果の活用まで一貫して管理する体制がない"},"1":{"comment":"大学発ベンチャーを製薬企業が買収。自社の一研究部門にする"},"2":{"comment":"経済的なコミュニティを形成"},"3":{"comment":"自社の研究施設を持つことも可能\n例）GAFA、NTT、野村総研"},"4":{"comment":"大学の近くに企業や投資家が集まる"},"5":{"comment":"特許等の研究成果を企業が独占できない。独占したら莫大な実施料の支払い義務を負う。"},"6":{"comment":"留学生を受け入れて海外企業とのつながりを創出"},"7":{"comment":"国立大学も含めてが自前で研究費の調達が必要。企業からの寄付講座などが無いと研究の存続が厳しい。\n→民間からお金が降りやすい研究テーマだけ継続。\n→実学偏重"},"8":{"comment":"学内or大学の近くに大学発ベンチャー"},"9":{"comment":"共同研究しても権利関係で揉める。\n例：小野薬品 vs 本庶佑氏\nオプジーボ訴訟"},"10":{"comment":"産学連携は研究費になっても大学の運営費にならない。"},"11":{"comment":"実用化に繋がりそうな技術シーズの情報発信が少なく、企業がキャッチアップしづらい。"},"12":{"comment":"技術指導・共同研究契約の手続きが煩雑"},"13":{"comment":"営業秘密や利益造反行為など共同研究・委託研究に関するルール・マネジメントが不十分"},"14":{"comment":"映画：「あのこは貴族」\n→学力で難関大学に入れても、教養面や生活面で差を感じる機会が多い（友人同士の遊び方、キャリア・結婚観、アートへの造詣の深さなど）。とはいえ、裕福な層が楽をしているわけでもない。政治家の息子は政治家、貴方の結婚相手はこのくらいの格がないと、というように、将来の選択肢がなかったり、親の期待値の高さに押しつぶされかねない。生育環境が人生のしがらみとなって現れる。"},"15":{"comment":"人間は社会性の生き物。他者からの眼差しで自分のありようを決めてしまい、不自由を感じることがある。\ncf: サルトル「地獄とは他人のことだ」"},"16":{"comment":"諸外国の大学院は授業料を支払うどころか、院生に給料が出るのが普通。"},"17":{"comment":"大学・大学院での経済支援が不透明であり、相当時間アルバイトに費やさざるを得ない学生に向けたカリキュラムにはなっていない。"},"18":{"comment":"教育格差\n親が大卒だと子も大卒になりやすい。\n・就職のしやすさなど、大卒のメリットがわかっている。\n・習い事を子供にさせている（子供が自発的にやりたいように仕向ける＝意図的養育（交渉のすすめ）↔︎放任的養育（親が子に命令し、交渉は望まない））。\n・そもそも非大卒者に比べて年収が高いことが多いため、子にとって大学進学への金銭的心理的ハードルが低い。"},"19":{"comment":"周囲（特に家族）に敬意を払われない状態で努力を続けて、かつ運も良くないと進学できない。"},"20":{"comment":"成績連動型奨学金だと絶対に成績を落とせないというプレッシャーが常にのしかかる。"},"21":{"comment":"大学の学費自体を値上げする\nBy慶應義塾長"},"22":{"comment":"多様な関わり方の余白を広げていくこと"},"23":{"comment":"コモニング：\n気ままに参加をし、それを受入れあい、管理する。関係性的であり実践的。"},"24":{"comment":"DAO\n→プロトコルが中心にあり、それに基づいて人々の行動が調整されている、そのエコシステム。PJに参加し、トークンを得る。"},"25":{"comment":"人間の直接的な介入なしに、定められたルールに基づいて行動。参加者の綿密なコミュニケーションや相互理解は不要"},"26":{"comment":"大学＝コモンズ空間：誰かに所有された空間ではないと思い、行動し合うこと、交渉し合うことで形作られた空間"},"27":{"comment":"人々がそれを私たちのコモンズだと思うこと、あるいはそう思って行動しあうこと、交渉しあうことで形作られる"},"28":{"comment":"Web3（自律分散型）\n→ユーザーからステークホルダーへ。"},"29":{"comment":"図書館や食堂は一般利用可能"},"31":{"comment":"法哲学の講義：二人でオレンジを取り合い。\n→法律はオレンジの所有権者を決めることはできても、需要に応じて皮（マーマレード作りたい）と果肉（果肉食べたい）に分けたらいいという解決策は出せない\n→法律だけ学んでいても社会では通用しない。"},"32":{"comment":"福沢諭吉\n貧困層には高等教育不要？→「智力」が成長しても、実地に活かせる地位や財産がなければ不満が溜まり「社会の安寧」を脅かす原因が増える"},"33":{"comment":"オンラインのつながりは便利で効率的な一方、人間関係が出来上がった人や意見を同じくする人同士で集まりがち？"},"34":{"comment":"立地が良かったり、綺麗なキャンパスがあると、志望度が上がる。キャンパスライフを送ることに意味がある。"},"35":{"comment":"就職後の階層関係を意識して良い大学を選ぶ"},"36":{"comment":"労働時間でカウントすると個人差がある。"},"37":{"comment":"学生と教師が結びつき、学生は教養と研究、教師は研究と教育を行う＋事務職は、金策を練ったり、大学としてのブランディングを実施。"},"38":{"comment":"大学教員がロールモデルになるには？\n→知的にかっこよくないとだめ\n→特権的な時間の自由を世間の常識とは違う価値観で使う。\n→クリエイティブな価値観を見せる＝博覧強記のかっこよさ"},"39":{"comment":"研究者の魅力は？\n→世間や時代に合わせずに世間に顧みられずとも、自己本位を貫くところ（↔︎他人本位な労働者）。趣味的な職業人でいる点。"},"40":{"comment":"国が大学セクターを動かすために、補助金をばら撒く→補助金申請につられると、研究・教育時間を削って、省庁の文書を読み込み、申請プレゼンなどの作業に時間を費やす\n→若手研究者は疲弊。"},"42":{"comment":"社会人キャリアのある人を教授として招聘"},"43":{"comment":"①教育、②研究、③社会（地域・経済・国際）貢献"},"44":{"comment":"「常識」をアンロックする。女性は意思決定に無意識に参加できないという刷り込みから解放\ncf 椙山女学園"},"45":{"comment":"地方大学は、当該地方に新たな若者（働き手）を供給している"},"46":{"comment":"学生に目標を決めずに迷う時間を与える"},"47":{"comment":"地方私大（特に女子大、短大、文系学部飲みの大学）の統廃合"},"48":{"comment":"最新の知識を体得して社会に出る"},"49":{"comment":"労働：生命を維持するために実施\n単一性・私的"},"50":{"comment":"社会人は「時間当たり採算」"},"51":{"comment":"限られた時間で成果を出す事が求められる"},"52":{"comment":"リカレント教育"},"53":{"comment":"活動：他者との共同行為、特に言葉を用いたコミュニケーション\n複数性・公共性"},"54":{"comment":"大学は、生活の心配をせずにその問いを持つことができ、果ての果てまで考え、対話するところ。"},"55":{"comment":"大学の使命は、文理融合を進めること。専門分野を複数持つ方がそれぞれの分野に役にたつ。\ncf: 数学者 岡潔「数学の中心は情緒」数学×文学など"},"56":{"comment":"どんな専門であろうがそれは入り口でしかなく、最終的に行き着くところは、自分自身の存在について考えること"},"57":{"comment":"実学から離れたところで、好奇心の赴くまま好きなことを学ぶ"},"58":{"comment":"公共的な問題について話し合い、複数的な意見を交換する共創空間が必要"},"59":{"comment":"どんな専門であろうがそれは入り口でしかなく、最終的に行き着くところは、自分自身の存在について考えること"},"60":{"comment":"様々な国、文化を持つ人々の知の共有と交流"},"61":{"comment":"14世紀から16世紀、大学の数が増加。単なる資格授与機関へ（知の形骸化）\n→宗教改革で宗派ごとに大学に断絶が起きる。\n国家形成でヨーロッパを横断する知のネットワークが作られにくくなる。\n→中世的な大学システムの機能不全。"},"62":{"comment":"科学革命\n(コペルニクスの地動説⇔同時代に重大な天文学的発見はない) 天文学者が本格的に印刷された数表等を利用⇒データの比較照合による仮説検証\n\n宗教改革\n教会堂と印刷本の闘い マルティン・ルター=豊富な出版の経験→印刷を教会批判に縦横に活用"},"63":{"comment":"16世紀から18世紀にかけて、グーテンベルクの活版印刷→本が普及→最先端の知を生み出す知識人は、大学の研究者ではなく、在野の著述家（出版を通じたネットワーク）"},"64":{"comment":"本の生産量の劇的増加=知識の大量複製・普及(情報爆発) ⇒知識を求めての放浪の時代の終わり=中世的大学システムの基盤の喪失 ⇒多数の本を集めての比較照合の時代の始まり"},"65":{"comment":"出版技術が発展するまでは、知識を求める際、その知識をもつ知識人に会いに行く or 修道院などに収蔵されている写本を読む\n→「学び」と「旅」は不可分な存在"},"66":{"comment":"近代の大学：学生・教師の協同組合(\"universitas\"自由な移動)⇔ 都市支配層"},"67":{"comment":"教会や広場などの都市施設を利用して授業実施→この集団が都市から都市へと渡り歩く→次々と新たな大学が都市の中に生み出される"},"68":{"comment":"ミネルヴァ大学\n2012年にアメリカで設立。\n・伝統的なキャンパスを持たない。\n・学生は世界各地を移動しながら学ぶ。\n→学問的なカリキュラム（オンライン）と異文化体験（寮が世界各国にある）を融合させた教育の提供。"},"69":{"comment":"1990年代後半以降、知識基盤社会への移行等により大学の教育・研究機能に対する社会の期待が極めて大きくなった。\nBUT大学教育は18歳人口の急激な減少に伴う大衆化(進学率の急激な上昇)や高等学校教育の多様化等により高等教育の質の確保が大きな課題"},"70":{"comment":"大卒であることではなく「どこの大学を出ているのか」で就職先が決まる"},"71":{"comment":"18歳人口の6割が大学+短大に進学\n※一部のエリートのためのものではない"},"72":{"comment":"大学は自国の文化復興のための国民国家の基盤と再定義"},"73":{"comment":"「フンボルト的大学観」：研究と教育を一体として結合させる。大学人を第一義的に研究者であると規定し、研究成果の披瀝が最高の教育であるとする考え方"},"74":{"comment":"文系におけるゼミナール（議論）、理系における実験室（観察と実験）の確立\n→学生と教師が共に学ぶ。"},"75":{"comment":"日本の大学設立の目的は国力強化（近代化の装置）\n→日本の国益に直結するエリート養成学校的"},"76":{"comment":"1930年代スペイン\nオルテガ：大学の使命は、1.教養教育2.専門職業人養成3.科学"},"77":{"comment":"２０世紀　アメリカ\nクラーク・カー『大学の効用』：現代の大学は教育・研究・奉仕の多機能を持った「マルチバーシティ」"},"78":{"comment":"PBL型教育"},"79":{"comment":"偏差値重視の受験内容ではなく、新しい入試の基準も必要かも"},"80":{"comment":"メーカーは量産化から販売までリスクを負う一方で、研究はリスクが少ないように映る。"},"81":{"comment":"就職で焦ってたから大学2年生からインターン\n・行動が打算だった=履歴書に書くため\n・心が貧しい、財布も貧しい\n・社会にお金ないですっていう漠然とした危機感\n・切り詰めなきゃ、のんびりしてちゃダメだ"},"82":{"comment":"給付型奨学金も振込先によっては両親から使い込まれる。結果、バイト三昧になる"},"83":{"comment":"国公立に行きたい人は、浪人できない恐怖。切羽詰まっている。\n→体育会系で脳筋になる。受かるか受からないかしか見れない。"},"86":{"comment":"大内さんの話\n同級生は恋バナ、推しのアイドル、MBTIの話をしてる。"},"87":{"comment":"大内さんの話\nコロナ下で入学。同一の目的（Web３に関心のある仲間など）で集うオンラインの仲間との間の方が交流が活発。ただ、主張はやや一方的かも。\n→直接会うことがない分、教授・同級生と仲良くなりにくかった。\n→特定のヒト・土地への依存度が低そう。"},"88":{"comment":"T教授・岡村さん（元准教授）\nコロナ下でオンラインゼミを開講した。思ったよりも闊達な議論が可能。顔色を窺わない分、発言することへの心理的安全性が上がったかも。一方、相手を見ているようで、自分の話をしているというコミュニケーションになっている。気を遣うのが難しいのかも。"},"89":{"comment":"義妹（大４）\n大学の学部は就職に役立ちそうなとこで選んだ。外大やったら空港で働けそうやし。哲学とかは就職と結びつきにくい。遠い感じ。"},"90":{"comment":"夫（機械・電子・電気系）が学生時代一番印象に残った授業は「山陰の歴史」「宗教と死生観」\n→わけわからん感じが良かった。工学と比べると異質すぎて。レポートに私見を入れる（工学系のレポートに私見はない）。\n→神学はロマンチックなところがあった。自分の人生の中で、キャリアチェンジしたのもロマンを求めたから。"},"91":{"comment":"夫の話\n大学には「余白」を楽しみに行った。キャンパスライフが大事で、いい就職先に行きたい感覚はゼロ。社会人になってからの方が高い給料の会社がいいな〜とか思うようになった。"},"92":{"comment":"一般教養科目で、色んな学部学科の人と交わる分、授業は1年目が一番楽しかった。"},"95":{"comment":"T教授\n論文めっちゃ書いてるし研究者として一流だろ、副学長もやったし事務できるだろ。その上お前、ゼミ生毎年３０人（※この数字は盛ってる）は出してるんだから、めちゃくちゃ優秀なんだよ、俺。\n→研究、管理、教育の三役をこなすのは至難の業。"},"96":{"comment":"岡村さんの話\n研究と教育、管理と教育とか二つならできる人いるんだよ。僕もゼミと研究は楽しかったよ。でも書類仕事多すぎるし断れへんしで、大学辞めて民間の研究所に行ってん。研究だけやってたら良くてリサーチ予算１０倍やで。"},"97":{"comment":"華道の先生（83）の話\n→シングルマザーで二人育てるんはしんどかったですよ。でも私は華道があったから疲れ切らなかった。華道を始めたのは働き始めてから。仕事から帰ったら子供しかないみたいにならなくて良かった。華道なんて役に立つもんじゃないけど、私は「無駄」に救われた。\n→大人になってから学びたいこと（教養）を学べる場があれば幸福度も上がる？"},"99":{"comment":"ナイトワーカーの友人の話\n→大学行ってみたかったよ。今でも哲学とか宗教系とかいいなーって思う。お金的に行けなくはないのよ。でも自分が１８歳の子達と昼間にキャンパスライフするのは、痒くて無理。"},"100":{"comment":"義妹（大４）の話\n・外大は在学中の海外留学が当たり前（地元高校にいた頃には想像できない文化）。\n・上記に感化されて留学すると、語学力の向上以上に、実地で異文化に触れる驚き・喜びを知った（それぞれの土地の文化や特産品の魅力を広めていきたい）。\n→大学は、学生にとって新たな選択肢をくれるところ"},"101":{"comment":"研究科に入ると先生や先輩後輩との距離が近い。同じ学問を追求する仲間ができる"}},"translations":{"There is no consistent system in place to manage from seed discovery to utilization of results.":["シーチ・ツー・イズ・ノー・コンシステンツ・システムを管理するためのシステムが存在していませた。","シーチ・ツー・イズ・ノー・コンシステンツ・システムを管理するためのシステムが存在していません。"],"Pharmaceutical companies acquiring university startups and integrating them into their research departments.":["薬物企業が大学スターツパードを購入して、それを自分の研究部門に組み合わせます。","薬物企業が大学スターツァプを購入して、それを自分の研究部門に組み合わせます。"],"経済的なコミュニティを形成する":["経済的なコミュニティを形成する","経済的なコミュニティを形成する"],"Having own research facilities is possible for companies like GAFA, NTT, and Nomura Research Institute.":["GAFA、NTT、なまる研究インストチッチュートのような企業にとって自分の研究設定を持っていることが可能です。","GAFA、NTT、なぞら研究インストチュートのような企業にとって自分の研究設定を持つことが可能です。"],"Companies and investors are gathering near universities.":["企業とインベスターは大学の近くに集合しています。","企業とイヴェスターは大学に近く集合しています。"],"Companies should not be able to monopolize research results like patents.":["企業はパテントのような研究結果をヒラル化することはできないほうです。","企業はパテントのような研究結果をヒラット化することはできません。"],"If a company monopolizes research results, they should bear the obligation to pay substantial implementation fees.":["企業が研究結果をモノポライズする場合、実行費用を支払しする赤い負債を負める必要があります。","企業が研究結果をモノポライズする場合、実行費用を支払いする超重要な費用を負める必要があります。"],"Accepting international students can create connections with overseas companies.":["国際生存者を受けることで外国企業との関連を作成することができます。","国際生存者を受けることで外国企業との関連を作成することが可能です。"],"Universities, including national ones, need to secure research funding independently.":["国立を含む大学は、研究資金を独立で確認する必要があります。","国立を含む大学は、独立して研究資金を確認する必要があります。"],"Without corporate-sponsored courses, it is challenging for research to continue.":["企業によりスポンサードされるコースは、研究を続けるために集合するのは難しいです。","企業のスポンサード・コースなし、研究を続けるには集中できないことになります。"],"Research on topics that attract funding from the private sector tends to be prioritized.":["プライベートセクターが集まるチャンネルに対して、有量の貢献を引き取る課金が優先される。","プライベートセクターが決定されるチャンネルに対して認識がある。"],"There is a bias towards practical learning.":["実用学習に向けのバイォスがある。","実用的学習に向けてバイォスがある。"],"大学の近くに大学発ベンチャーを設立することが重要である。":["大学の近くに大学発ベンチャーを設立することが重要である。","大学の近くに大学発ベンチャーを設立することが重要である。"],"Collaborative research can lead to disputes over rights.":["協同研究は正当性に関連することがあるが、正当性に関連することで調べることがある。","協同研究は正当に決定に関連することがある。"],"Example: Ono Pharmaceutical vs. Honjo Tasuku - Opdivo lawsuit.":["例：大野藤薬能と本田由伸のオプディーボーブースイトコート・設置設置。","例：大野藤薩と本田由佳 - Opdivo設置設計に関連する認識。"],"Industry-academia collaboration research funding does not contribute to university operating expenses.":["インドストリー・アカデミアとの協会研究課金は大学の遊行資源に負のない。","インドストリー-学術博物は大学の運動資源に貢献しない。"],"Information dissemination on emerging technologies that could lead to practical applications is limited, making it difficult for companies to catch up.":["出現する技術の情報漏れは実用に影響することがあるため、企業がキャッチアップを認めるのが難しい。","現象に実用することができるエメルジング・テクノロジーの情報演算が限り、企業が追加するには難しい。"],"技術指導・共同研究契約の手続きが煩雑":["技術指導・共同研究契約の手続きが煩雑","技術指導・共同研究契約の手続きが煩雑"],"The rules and management regarding joint research and commissioned research, such as trade secrets and profit rebellion, are insufficient.":["共同研究と証言研究の規則と管理は、ネット・シークレットと利益反対などの不安なことで足りません。","ルールと管理に関連する解決と妥容研究など、トレードシークレットと利益反射は不安。"],"Entering prestigious universities based on academic performance may not bridge the gap in cultural and lifestyle differences, leading to disparities in various aspects of life.":["学業背景に基づく計画に基づく大学入象は文化と生活・精神の道の間の間に潜り、異なることに対する。","学業能力に基づく学校に入学することで文化と生活・ライフスタイルの違いを突破させないことがあり。"],"Despite academic achievements, individuals may still face challenges in social interactions, career choices, marriage expectations, and appreciation for the arts, reflecting the influence of upbringing and societal expectations.":["学術的な成績を受けても、社会との交渉、キモク選択、婚活の期待、お客の定量になるという問題に適しくなることがある。","学術的な成績を受けても、社会との交渉、キモノ選択、婚活の期待、参照に影響を受めることがあることを表す。"],"人間は社会性の生き物であり、他者からの眼差しで自己を定義し、不自由を感じることがある。":["人間は社会性の生き物であり、他者からの眼差しで自己を定義し、不自由を感じることがある。","人間は社会性の生き物であり、他者からの眼差しで自己を定義し、不自由を感じることがある。"],"サルトルの言葉「地獄とは他人のことだ」を参考にすると、他者との関係が人間にとって重要であることが示唆される。":["サルトルの言葉「地獄とは他人のことだ」を参考にすると、他者との関係が人間にとって重要であることが示唆される。","サルトルの言葉「地獄とは他人のことだ」を参考にすると、他者との関係が人間にとって重要であることが示唆される。"],"Many foreign graduate schools pay stipends to their students instead of charging tuition fees.":["多くの外国の学生は、学費を記憶しないで、学生に従うための指額を支援する。","多くの外国の学生は、学費を記憶しないで、学生に対して指額を支払いする。"],"Financial support in universities and graduate schools is opaque, leading students to spend significant time on part-time jobs.":["大学と学生の財動支援は不明で、学生がパーツタイムジョブに時間を費やすことに費いする。","大学と学生の財動支援は不透で、学生がパーツタイムジョプに時間を費やすことを強化する。"],"The curriculum does not cater to students who have to spend a considerable amount of time on part-time jobs due to lack of transparency in financial support.":["カリキュラムは、財動支援の不明により、パーツタイムジョブに時間を費やす必要がある生延作に適していなる。","カリキュラムは、財動支援の不透により、パーツタイムジョプに時間を費やす必要がある生延作をする学生に適している。"],"Parental education level influences children's educational attainment":["親の教育レベアが実践される子主の教育道","教育を受ける子主の教育経緯は子主の教育達成に影響を与える"],"Children of college graduates are more likely to pursue higher education due to understanding the benefits of a degree, engaging in extracurricular activities, and lower financial barriers.":["学生の子は、学位の相対利益を理解するために、学会の相対活動を行うために、外部演算を行うために、低財動に対して、もっと高い学位を追い詰める可能性が高い。","学生の学生は、学位の目的の理解を図るため、学外活動に参加することと、低財動のバリアーを低下させるために、高学位を認める可能性が高い。"],"Respect from the surroundings, especially family, is necessary to continue efforts, and without luck, one cannot advance in education.":["周囲からの尊重は、特に家族からのものである。これなぜなのかは、教育に進行するためには、それには対しての幸福が必要である。","周囲からの尊重は、特に家族からの尊重は、動くためには教育を続けるために必要である。"],"Scholarships tied to academic performance create constant pressure to maintain high grades.":["学生の成績に終わりの尊重を保持するために、学生は高い点数を経験しようとする。","学生の学術的成績に終わりの尊重を依存させる学生には、高い点数を経験したことを繰り返す必要がある。"],"慶應義塾長 suggests increasing university tuition fees.":["勇敢な学長は大学の授業料を引き上げることを提案しています。","勇敢な学習者長 suggests increasing university tuition fees."],"Expanding the margins of diverse ways of engagement.":["多様な関与の方法の余白を拡大する。","多様な関与の余地を拡大する。"],"コモニング: Participating freely, accepting and managing it. Relationship-oriented and practical.":["コモニング：自由に参加し、受け入れ、管理する。関係重視で実践的。","コミュニケーション: 自由に参加し、受け入れ、管理する。関係志向的で実践的。"],"DAOはプロトコルを中心に人々の行動を調整するエコシステムであり、PJに参加してトークンを得ることができる。":["DAOはプロトコルを中心に人々の行動を調整するエコシステムであり、PJに参加してトークンを得ることができる。","DAOはプロトコルを中心に人々の行動を調整するエコシステムであり、PJに参加してトークンを得ることができる。"],"人間の直接的な介入なしに、定められたルールに基づいて行動。":["人間の直接的な紹介なしに、定められたルールに基づいて行動。","人間の直接的な紹介なしに、定められたルールに基づいて行動。"],"参加者の綿密なコミュニケーションや相互理解は不要":["参加者の密なコミュニケーションや相互理解は不要","参加者の密なコミュニケーションや相互理解は不要"],"Universities as common spaces: Spaces shaped by collective actions, negotiations, and interactions, not owned by anyone.":["大学は共通の空間として：誰にも所有されていない、集団行動、交渉、相互作用によって形作られた空間。","大学は共通の空間として: 誰にも所有されていない、集団行動、交渉、相互作用によって形成された空間。"],"人々がコモンズとして考え、行動し、交渉することで形成される。":["人々がコモンズとして考え、行動し、交渉することで形成される。","人々がコミュニケーションとして考え、行動し、交渉することで形成される。"],"Web3 (self-regulating decentralized) shifts power from users to stakeholders.":["Web3（自己規制型分散型）はユーザーからステークホルダーへの権力の移行。","Web3（自己規制型分散型）はユーザーからステークホルダーへの権力移行。"],"Libraries and cafeterias are open to the general public.":["図書館やカフェテリアは一般に公開されています。","図書館やカフェテリアは一般に開放されています。"],"法律は所有権を決めるが、需要に応じた解決策を提供できない":["法律は所有権を確定するが、必要に応じた解決策を提供できない","法律は所有権を確定するが、必要に応じた解決策を提供できない"],"法律だけでは社会で通用しない":["法律だけでは社会で通用しない","法律だけでは社会で通用しない"],"Is higher education unnecessary for the impoverished? - Even if intelligence grows, without practical positions or assets, dissatisfaction accumulates, increasing the causes threatening 'social peace.'":["貧困層にとって高等教育は不要か？ - 知性が高まっても、実務のポジションや資産がないと、不満が蓄積され、'社会平和'を脅かす原因が増加する","貧困層にとって高等教育は不要か？ - 知性が高まっても、実務のポジションや資産がないと、不満が蓄積され、'社会平和'を脅かす原因が増加する"],"Online connections can be convenient and efficient, but they tend to gather people with similar opinions or backgrounds.":["オンラインのつながりは便利で効率的かもしれないが、似た意見やバックグラウンドを持つ人々が集まりやすい","オンラインのつながりは便利で効率的かもしれないが、似た意見やバックグラウンドを持つ人々が集まりやすい"],"A good location and a beautiful campus can increase the desirability of a university.":["良い立地と美しいキャンパスは大学の魅力を高めることができる","良い立地と美しいキャンパスは大学の魅力を高めることができる"],"Having a meaningful campus life experience is important for students.":["意義あるキャンパスライフの経験は学生にとって重要だ","意義あるキャンパスライフの経験は学生にとって重要だ"],"Consider the hierarchy of positions after graduation when choosing a good university.":["良い大学を選ぶ際には卒業後のポジションの階層を考慮する","良い大学を選ぶ際には卒業後のポジションの階層を考慮する"],"There are individual differences in how labor hours are counted.":["労働時間のカウント方法には個人差がある","労働時間のカウント方法には個人差がある"],"Students and teachers collaborate, with students focusing on liberal arts and research, and teachers on research and education. Administrative staff work on fundraising and university branding.":["学生と教師は協力し、学生は教養と研究に焦点を当て、教師は研究と教育に焦点を当てる。 管理職は資金調達と大学のブランディングに取り組む","学生と教師は協力し、学生は教養と研究に焦点を当て、教師は研究と教育に焦点を当てる。 管理職は資金調達と大学のブランディングに取り組む"],"University professors should be role models by being intellectually cool.":["大学教授は知的にクールであることでロールモデルであるべきだ","大学教授は知的にクールであることでロールモデルであるべきだ"],"Using privileged time freedom with a different value system from societal norms.":["社会的な規範とは異なる価値観を持つ特権的な時間の自由を利用する。","社会的な規範とは異なる価値観を持つ特権的な時間の自由を利用する。"],"Showing a creative perspective equals the coolness of erudition.":["創造的な視点を示すことは教養のクールさに等しい。","創造的な視点を示すことは博識のクールさに等しい。"],"Researchers are attractive for their self-centeredness and hobby-like approach to their profession.":["研究者は自己中心的で趣味のようなアプローチを持つことで魅力的である。","研究者は自己中心的で趣味のようなアプローチを持つことで魅力的である。"],"Government distributing subsidies to drive the university sector can lead to time-consuming administrative tasks for researchers and educators":["政府が大学部門を推進するために補助金を配布することは、研究者や教育者に時間のかかる行政業務をもたらす可能性がある","政府が大学部門を牽引するために補助金を配布することは、研究者や教育者にとって時間を取られる行政業務を招く可能性がある"],"Young researchers may experience exhaustion due to the administrative burden caused by grant applications.":["助成金申請による行政負担によって若手研究者が疲弊する可能性がある。","助成金申請による行政負担によって若手研究者は疲労を経験するかもしれない。"],"Invite professionals with real-world experience to become professors.":["実務経験豊富な専門家を教授に招待する。","実務経験豊富な専門家を教授に招待する。"],"Education":["教育","教育"],"Research":["研究","研究"],"Contribution to society (local, economic, international)":["社会への貢献（地域、経済、国際）","社会への貢献（地域、経済、国際）"],"Unlocking 'common sense'. Freeing women from the conditioning that they cannot participate unconsciously in decision-making.":["『常識』の解除。女性が無意識に意思決定に参加できないという制約から解放する。","『常識』の解除。女性が無意識に意思決定に参加できないという制約から解放する。"],"Local universities are supplying new young people (workers) to their respective regions.":["地元の大学はそれぞれの地域に新しい若者（労働者）を供給しています。","ローカルの大学はそれぞれの地域に新しい若者（労働者）を供給しています。"],"Allowing students to explore without setting specific goals.":["具体的な目標を設定せずに学生が探求できるようにすること。","具体的な目標を設定せずに学生が探求できるようにする。"],"地方私立大学の統合や統廃合について検討が必要":["地方私立大学の統合や分合について調査が必要","地方私立大学の統合や統廃合について検討が必要"],"最新の知識を身につけて社会に貢献する":["最新の知識を身につけて社会に貢献する","最新の知識を身につけて社会に貢献する"],"労働：生命を維持するために実施":["労働：生活を維持するために実施","労働：生命を維持するために実施"],"単一性・私的":["単一性・私の","単一性・私的"],"社会人は「時間当たり採算」":["社会人は「時間当たり計算」","社会人は「時間当たり採算」"],"成果を出すためには限られた時間が求められる。":["成果を出すためには限られた時間が求められる。","成果を出すためには限られた時間が求められる。"],"Recurrent education":["Recurrent education","再教育"],"共同行為における言葉の重要性":["共同行為として行われる言葉の重要性","共同行為における言葉の重要性"],"複数性と公共性の関連性":["複数性と共同性の関連性","複数性と共同性の関連性"],"大学は、生活の心配をせずにその問いを持つことができ、果ての果てまで考え、対話するところ。":["大学は、生活の核心をせずにその問いを持つことができ、果ての果てまで考え、対話するところ。","大学は、生活の核心を示さずにその問いを持つことができ、果ての果てまで考え、対話するところ。"],"Universities should promote the integration of arts and sciences.":["Universities should promote the integration of arts and sciences.","大学は、芸術と科学の統合を推進すべきです。"],"Having expertise in multiple fields can be beneficial for each respective field.":["複数の分野に専門知識を持つことは、それぞれの分野にとって有益である可能性があります。","複数の分野で専門知識を持つことは、それぞれの分野にとって有益である可能性があります。"],"Regardless of the field of expertise, it all leads back to reflecting on one's own existence.":["専門分野に関係なく、すべては自己の存在を反映することにつながります。","専門分野に関係なく、すべては自己の存在を考え直すことにつながります。"],"学問から離れて、好奇心に従って興味のあることを学ぶことが重要である。":["学問から離れて、好奇心に従って興味のあることを学ぶことが重要である。","学問から離れて、好奇心に従って興味のあることを学ぶことが重要である。"],"共創空間が必要で、公共の問題について話し合い、複数の意見を交換することが重要。":["共創空間が必要で、公共の問題について話し合い、複数の意見を交換することが重要。","共創空間が必要で、共同の問題について話し合い、複数の意見を交換することが重要。"],"Regardless of the specialization, it all leads to reflecting on one's own existence.":["Regardless of the specialization, it all leads to reflecting on one's own existence.","専門化に関係なく、すべては自己の存在を考え直すことにつながります。"],"Sharing and exchanging knowledge among people from diverse countries and cultures.":["異なる国々や文化からの人々との知識の共有と交換。","異なる国々や文化からの人々との知識の共有と交換。"],"大学の数が増加し、知の形骸化が進んだ":["大学の数が増加し、知の形骸化が進んだ","大学の数が増加し、知の形骸化が進んだ"],"宗教改革や国家形成により大学システムの機能不全が露呈した":["宗教改革や国家形成により大学システムの機能不全が露呈した","宗教改革や国家形成により大学システムの機能不全が露呈した"],"科学革命において、データの比較照合による仮説検証が重要であった。":["科学革命において、データの比較照合による仮説検証が重要であった。","科学革命において、データの比較照合による仮説検証が重要であった。"],"宗教改革では、印刷技術が教会批判に活用された。":["宗教改革では、印刷技術が教会批判に活用された。","宗教改革では、印刷技術が教会批判に活用された。"],"From the 16th to the 18th century, Gutenberg's printing press led to the widespread availability of books, shifting the production of cutting-edge knowledge from university researchers to independent writers and publishers.":["16世紀から18世紀にかけて、グーテンベルクの印刷機が書籍の普及をもたらし、最先端の知識の生産が大学研究者から独立した作家や出版社へと移行した。","16世紀から18世紀にかけて、グーテンベルクの印刷機が登場し、書籍の普及が進み、最先端の知識の生産が大学研究者から独立した作家や出版社に移行した。"],"The dramatic increase in book production leads to the mass duplication and dissemination of knowledge, marking the end of the era of wandering in search of knowledge and the loss of the foundation of the medieval university system, ushering in an era of comparing and cross-referencing numerous books.":["書籍の大量生産の急増は知識の大量複製と普及をもたらし、知識を求めてさまよう時代の終焉と中世大学システムの基盤の喪失を象徴し、多数の書籍を比較照合する時代を迎えた。","書籍の大量生産の急増により、知識の大量複製と普及がもたらされ、知識を求めて放浪する時代が終わり、中世の大学システムの基盤が失われ、多数の書籍を比較し交差参照する時代が幕を開けた。"],"Before the advancement of publishing technology, seeking knowledge involved meeting knowledgeable individuals or reading manuscripts stored in places like monasteries.":["出版技術の進歩以前、知識を求めることは知識豊富な個人と出会うか修道院などに保管された写本を読むことを含んでいた。","出版技術の進歩以前、知識を求めることは、知識豊富な個人に会うか修道院などに保管された写本を読むことを意味した。"],"The concepts of 'learning' and 'travel' are inseparable.":["「学び」と「旅」の概念は切り離せない。","「学び」と「旅行」の概念は切り離せない。"],"Modern universities: Cooperation between students and teachers ('universitas' free movement) vs. urban ruling class.":["現代の大学：学生と教師の協力（自由な移動の「universitas」）対都市支配階級。","現代の大学：学生と教師の協力（自由な移動の「universitas」）対都市支配階級。"],"Using city facilities like churches and squares for classes can lead to the creation of new universities in cities as people move from city to city.":["教会や広場などの都市施設を授業に利用することで、都市間を移動する人々によって都市に新しい大学が創設される可能性がある。","教会や広場などの都市施設を授業に利用することで、都市に新しい大学が生まれる可能性があり、人々が都市から都市へ移動する中で大学が創設される。"],"Minerva University was established in the United States in 2012 without a traditional campus.":["ミネルバ大学は2012年に伝統的なキャンパスを持たずにアメリカに設立された。","ミネルバ大学は2012年に伝統的なキャンパスを持たずにアメリカに設立された。"],"Students learn while traveling around the world, combining academic curriculum (online) with cross-cultural experiences (residences in various countries).":["生存者は世界を通して学びをしている間に、学術カリキュラム(オンライン)と異ならなクロスカルッチャル・インターナドイン(異常な国のレジデンス)を組合する。","生存者は世界を通して学びをします、学術カリキュラム(オンライン)と異ならなクロスカルッチャルエクスプエリエンス(異常な国のレジデンスで)を組合します。"],"Transition to a knowledge-based society has increased societal expectations on university education and research functions since the late 1990s.":["知法ベース社会に移動してきると、運用と研究関係は1990年以来の後にウニブサイト教育と研究機能の社会的期待が高まる。","知法ベース社会に移動していくと、運用法は1990年以来の後に学校教育と研究関係に強化した。"],"However, challenges such as the massification of university education due to a rapid decline in the population of 18-year-olds and the diversification of secondary education pose significant obstacles to ensuring the quality of higher education.":["しかし、、学校教育の大変化により18歳の人口の連続的な減少により、主な問題として高級教育の品質を確認するには大きい集合が必要な防止物とする。","しかし、18歳の人口の連続的な減少によくよくなる大学教育の大学化と二段化の多次化は、高学教育の品質を確認するのに大きい難易を定します。"],"Employment opportunities are often determined by the university one graduates from, rather than just having a bachelor's degree.":["提供機会は常に大学から卒論するというより、卒論者としての学習だけでなく、卒学者としての学習だけでなく。","提供機会は常に大学から卒論している大学により、単に学士の学乗を持っているために決めることがあります。"],"60% of the 18-year-old population goes to universities or junior colleges":["18歳人口の60%が大学へ行くか、ジュニアコレージへ行くか","18歳人口の60%が大学へ行くか、ジュニアコレージへ行くか"],"Universities are not just for the elite":["大学は経済的に第一ではない","大学は経済的ではない"],"Universities are the foundation for the revitalization of national culture.":["大学は国民文化の内心の内心である。","大学は国民文化の内心の内心です。"],"「フンボルト的大学観」において、研究と教育を一体として結合させる。":["「フンボルト的大学観」において、研究と教育を一体として結合させる。","「フンボルト的大学観」において、研究と教育を一体として結合させる。"],"大学人を第一義的に研究者と規定し、研究成果の披瀝が最高の教育であるとする考え方。":["大学人を第一義的に研究者と規定し、研究成果の披瀝が最高の教育であるとする考え方。","大学人を第一義的に研究者と規定し、研究成果の披瀝が最高の教育であるとする考え方。"],"Establishing seminars for humanities and laboratories for sciences to facilitate learning for both students and teachers.":["人文学のセミナーと科学のラボラッブを使用して学生と教師の取り組みを助めるためのセミナーを立てる。","人文系のセミナーと科学のラボラッブを使用して学生と教師の取り組みを助めます。"],"The purpose of establishing universities in Japan is to strengthen the national power and serve as a tool for modernization.":["日本における大学の設立目的は、国家力を強化し、近代化のための道具として機能することです。","日本の大学を立ち上げる目的は国宝を強化し、現代化のトールとして使用するツールとする。"],"Universities in Japan are seen as elite training schools that directly contribute to the national interest.":["日本の大学は、国益に直接貢献するエリート養成学校と見なされています。","日本の大学は、精神なトレーニングスクールとして、国家の興奮に相当する。"],"Ortega in the 1930s Spain highlighted the mission of universities: 1. Liberal education, 2. Professional training, 3. Science.":["1930年代のスペインでオルテガは大学の使命を強調しました：1. リベラル教育、2. 専門教育、3. 科学。","1930年のスペインではウニビーシティの任務を経験したウニビーシティの任務を経験した。 1.リベラル教育、2.プロフェドショナル・トレーニング、3.サイエンス。"],"Clark Kerr's 'The Uses of the University' emphasizes the multifunctionality of modern universities in education, research, and service.":["Clark Kerrの『大学の使命』は、現代の大学の教育、研究、サービスにおける多機能性を強調しています。","Clark Kerrの『大学の使用方式』は、現代の大学の多機能性を教育、研究、サーベイスで結合することを強化する。"],"PBL型教育":["PBL型教育","PBL型教育"],"新しい入試基準の必要性について考えるべきかもしれない。":["新しい入試基準の必要性について考えるべきかもしれない。","新しい入試基準の必要性について考えるべきかもしれない。"],"Manufacturers bear risks from mass production to sales, while research appears to have less risk.":["製造業者は大量生産から販売までのリスクを負い、一方、研究はリスクが少ないように見える。","製造商は、大金生産から負けるリスクを貧し、研究は少しリスクがあるように見える。"],"焦っていたため、大学2年生からインターンを始めた。":["熱心になったため、大学2年生からインターンを始めた。","焦っていたため、大学2年生からインターンを始めた。"],"行動が打算的で、履歴書に書くためだった。":["行動が計算的で、履歴書に書くためだった。","行動が打算的で、履歴書に書くためだった。"],"心が貧しく、財布も貧しかった。":["心が貧しく、財布も貧しかった。","心が貧しく、財布も貧しかった。"],"漠然とした社会にお金がないという危機感を抱いていた。":["漠然とした社会にお金がないという危機感を抱いていた。","漠然とした社会にお金がないという危機感を抱いていた。"],"切り詰めなければ、のんびりしていてはいけないと感じていた。":["切り離されなければ、のんびりしていてはいけないと感じていた。","切り離されるなら、のんびりしていてはいけないと感じていた。"],"Scholarships with direct payments to parents can sometimes be misused, leading students to work multiple jobs.":["直接支払いの奨学金は、学生が複数の仕事をすることにつながり、時に誤用されることがあります。","直接支払いを受け取る奨学金は、学生が複数の仕事をすることにつながり、時に誤用されることがある。"],"Students who want to attend national universities fear not being able to take a gap year. They feel pressured and are becoming more focused on physical activities rather than academics, as they can only see whether they will pass the exams or not.":["国立大学に進学したい学生たちは、1年間の休学ができないことを恐れています。彼らはプレッシャーを感じ、学業よりも身体活動に焦点を当てるようになっています。彼らは試験に合格するかどうかしか見ることができません。","国立大学に進学したい学生たちは、1年間の休学を取れないことを恐れている。彼らはプレッシャーを感じ、学業よりも身体活動に焦点を当てるようになっており、試験に合格するかどうかしか見えないため。"],"同級生は恋愛や推しのアイドル、MBTIについて話している。":["同級生は恋愛や推しのアイドル、MBTIについて話しています。","同級生は恋愛や推しのアイドル、MBTIについて話している。"],"Under COVID-19, online interactions with like-minded individuals can be more active, but may lead to one-sided arguments.":["COVID-19の下、志を同じくする人々とのオンラインでのやり取りが活発になることがありますが、片方向の議論につながる可能性があります。","COVID-19下では、志を同じくする人々とのオンラインでのやり取りが活発になることがあるが、片方向の議論につながるかもしれない。"],"Difficulty in forming close relationships with professors and classmates due to lack of in-person interactions.":["対面でのやり取りがないため、教授やクラスメートとの親密な関係を築くことが難しい。","対面でのやり取りがないため、教授やクラスメートとの親密な関係を築くことが難しい。"],"Lower dependency on specific individuals or locations.":["特定の個人や場所への依存が低下しています。","特定の個人や場所への依存が低い。"],"Online seminars during the pandemic allowed for more open discussions and increased psychological safety for participants.":["パンデミック中のオンラインセミナーは、参加者にとってよりオープンな議論を可能にし、心理的安全性を高めました。","パンデミック中のオンラインセミナーは、参加者にとってよりオープンな議論を可能にし、心理的安全性を高めた。"],"However, online communication may lead to challenges in maintaining a sense of connection and attentiveness during discussions.":["ただし、オンラインコミュニケーションは、議論中につながりや注意力を維持することに課題をもたらす可能性があります。","ただし、オンラインコミュニケーションは、議論中につながりや注意力を維持することに課題をもたらすかもしれない。"],"学生は大学の学部を将来の就職に関連して選ぶ傾向がある。":["学生は大学の学部を将来の就職に関連して選ぶ傾向がある。","学生は大学の学部を将来の就職に関連して選ぶ傾向がある。"],"一部の学部（例：哲学）は就職との関連性が低いとの認識がある。":["一部の学部（例：哲学）は就職との関連性が低いとの認識がある。","一部の学部（例：哲学）は就職との関連性が低いとの認識がある。"],"The student found history and religious studies courses to be the most memorable during their university days.":["大学生活を最も記憶に残るものと感じたのは、歴史と宗教学の授業だった。","学生は大学時代に歴史と宗教学の授業が最も記憶に残ると感じた。"],"The diversity and uniqueness of these courses compared to engineering made them stand out.":["これらの授業の多様性と独自性は、工学と比較して際立っていた。","これらの授業の多様性と独自性は、エンジニアリングと比較して際立っていた。"],"The student appreciated the opportunity to include personal opinions in reports for these courses, unlike in engineering reports.":["学生は、これらの授業のレポートに個人的な意見を盛り込む機会を評価しており、工学のレポートとは異なる。","学生は、これらの授業のレポートに個人的な意見を盛り込む機会を評価し、エンジニアリングのレポートとは異なると感じた。"],"The student found a romantic aspect in theology, which influenced their career change driven by a search for romance in life.":["学生は神学にロマンチックな側面を見出し、人生におけるロマンスを求める中でキャリアチェンジに影響を受けた。","学生は神学にロマンチックな側面を見出し、人生におけるロマンスを求める中でキャリアチェンジに影響を受けた。"],"大学生活を楽しむ余白が大切で、就職先よりもキャンパスライフを重視する考え方がある。":["大学生活を楽しむ余裕が大切で、就職先よりもカンパスライフを重視する考え方がある。","大学生活を楽しむ余裕が大切で、就職先よりもカンパスライフを重視する考え方がある。"],"社会人になると高給料の会社を重視する傾向がある。":["社会人になると高給料の会社を重視する傾向がある。","社会人になると高給料の会社を重視する傾向がある。"],"General education courses where students from various departments interact are most enjoyable in the first year.":["各学部の学生が交流する総合教育科目は、1年生の中で最も楽しい。","各学部の学生が交流する総合教育科目は、1年次に最も楽しい。"],"Balancing research, management, and education roles is a challenging task.":["研究、管理、教育の役割をバランスよくこなすことは、挑戦的な課題である。","研究、管理、教育の役割をバランスよくこなすことは、挑戦的な課題である。"],"岡村さんは大学を辞めて民間の研究所に行った":["山村さんは大学を辞めて民間の研究所に行った","山村さんは大学を辞めて民間の研究所に行った"],"研究だけに集中することでリサーチ予算が10倍になった":["研究だけに集中することでリサーチ予算が10倍になった","研究だけに集中することでリサーチ予算が10倍になった"],"Starting ikebana (Japanese flower arrangement) after beginning work helped me not feel completely exhausted from raising two children as a single mother. It was a relief from feeling like I only had children when coming home from work. Ikebana may not be useful, but it saved me from feeling 'useless'.":["仕事を始めてからいけばな（日本の花道）を始めることは、シングルマザーとして2人の子供を育てる際に完全に疲れ果てたと感じないように助けてくれました。仕事から帰宅したときには子供しかいないと感じることから解放されました。いけばなは役に立たないかもしれませんが、私を「無価値」に感じさせることから救ってくれました。","仕事を始めてから生活が大変なシングルマザーとして完全に疲れ果てたと感じなくなりました。仕事から帰宅するときには子供しかいないと感じることから解放されました。生け花は役に立たないかもしれませんが、私を「無価値」に感じさせることから救ってくれました。"],"Could having a place to learn what you want to learn (culture) as an adult increase happiness?":["大人になってから学びたいこと（文化）を学ぶ場所が幸福感を高める可能性があるか？","大人として学びたいこと（文化）を学ぶ場所が幸福感を高める可能性があるかもしれませんか？"],"Night worker's friend's story: They wanted to try going to university. They still think philosophy and religious studies are interesting. They can afford it financially, but they find it uncomfortable to live the campus life with 18-year-old students during the day.":["夜勤労働者の友人の話：大学に行ってみたいと思っていた。今でも哲学や宗教学は面白いと思っている。経済的に余裕があるが、昼間に18歳の学生とキャンパスライフを共にするのは不快だと感じている。","夜勤労働者の友人の話：大学に行ってみたいと思っていました。今でも哲学や宗教学は興味深いと考えています。経済的に余裕がありますが、昼間に18歳の学生とキャンパスライフを共にするのは不快だと感じています。"],"Studying abroad during university is common at certain universities":["大学での留学は特定の大学では一般的です","大学での留学は特定の大学では一般的です"],"Studying abroad provides opportunities to experience different cultures and products":["留学は異なる文化や製品を体験する機会を提供します","留学は異なる文化や製品を体験する機会を提供します"],"Entering a research department allows for close relationships with professors, seniors, and juniors.":["研究部門に入ることで教授、先輩、後輩との密接な関係を築くことができます。","研究部門に入ることで教授、先輩、後輩との密接な関係を築くことができます。"],"Having peers who pursue the same field of study can be beneficial.":["同じ専攻を追求する仲間がいることは有益である。","同じ専攻を追求する仲間がいることは有益かもしれません。"],"University Research and Industry Collaboration":["大学研究と産業の協力","大学の研究と産業の連携"],"Evolution of Social Engagement in Universities":["大学における社会的関与の進化","大学における社会的関与の進化"],"Evolution of University Role":["大学の役割の進化","大学の役割の進化"],"Evolution of University Experience":["大学体験の進化","大学体験の進化"],"Evolution of University Role and Trends":["大学の役割とトレンドの進化","大学の役割とトレンドの進化"],"Changing Role of Universities":["大学の変化する役割","大学の役割の変化"],"Challenges in Higher Education":["高等教育の課題","高等教育の課題"],"Evolution of Educational Approaches":["教育アプローチの進化","教育アプローチの進化"],"Argument":["議論","議論"],"Original comment":["オリジナルコメント","元のコメント"],"Representative arguments":["代表的な議論","代表的な議論"],"Open full-screen map":["フルスクリーンマップを開く","フルスクリーンマップを開く"],"Back to report":["レポートに戻る","レポートに戻る"],"Hide labels":["ラベルを非表示","ラベルを非表示"],"Show labels":["ラベルを表示","ラベルを表示"],"Show filters":["フィルタを表示","フィルターを表示"],"Hide filters":["フィルタを非表示","フィルターを非表示"],"Min. votes":["最小投票数","最小投票数"],"Consensus":["コンセンサス","コンセンサス"],"Showing":["表示中","表示中"],"arguments":["議論","議論"],"Reset zoom":["ズームをリセット","ズームをリセット"],"Click anywhere on the map to close this":["地図のどこかをクリックして閉じる","地図のどこかをクリックして閉じる"],"Click on the dot for details":["詳細を見るために点をクリック","詳細を見るために点をクリック"],"agree":["同意する","同意する"],"disagree":["同意しない","同意しない"],"Language":["言語","言語"],"English":["英語","英語"],"of total":["の合計","の合計"],"Overview":["概要","概要"],"Cluster analysis":["クラスター分析","クラスター分析"],"Representative comments":["代表的なコメント","代表的なコメント"],"Introduction":["導入","導入"],"Clusters":["クラスター","クラスター"],"Appendix":["付録","付録"],"This report was generated using an AI pipeline that consists of the following steps":["このレポートは、以下の手順で構成されるAIパイプラインを使用して生成されました","このレポートは、以下の手順で構成されるAIパイプラインを使用して生成されました"],"Step":["ステップ","ステップ"],"extraction":["抽出","抽出"],"show code":["コードを表示","コードを表示"],"hide code":["コードを非表示","コードを非表示"],"show prompt":["プロンプトを表示","プロンプトを表示"],"hide prompt":["プロンプトを非表示","プロンプトを非表示"],"embedding":["埋め込み","埋め込み"],"clustering":["クラスタリング","クラスタリング"],"labelling":["ラベリング","ラベリング"],"takeaways":["持ち帰り","持ち帰り"],"overview":["概要","概要"],"Japanese":["日本語","日本語"],"Hiromi Ouchi KJ Method":["大内宏美KJ法","大内宏美KJ法"],"How has the role of universities changed over the past decades, and what trends will shape their future?":["過去数十年間で大学の役割はどのように変化しましたか、そして将来を形作るトレンドは何ですか？","過去数十年間で大学の役割はどのように変化しましたか、そして将来を形作るトレンドは何ですか？"],"The comments highlight challenges in managing research from seed discovery to implementation, with concerns about industry-academia collaborations, patent monopolies, funding sources, and administrative burdens on researchers. Issues raised include the integration of university startups into pharmaceutical companies, the need for independent research funding for universities, and the prioritization of practical learning and industry-funded research. Disputes over rights in collaborative research and the limited dissemination of emerging technologies for practical applications are also noted. The comments underscore the complex balance required in research, management, and education roles within the university sector.":["コメントは、種子の発見から実装までの研究の管理における課題を強調し、産業と学術の連携、特許の独占、資金源、研究者への行政上の負担について懸念があることが示されています。提起された問題には、大学のスタートアップの製薬会社への統合、大学の独立した研究資金の必要性、実践的な学習と産業資金による研究の優先順位が含まれています。共同研究における権利の争いや実用技術の限られた普及に関する問題も指摘されています。コメントは、大学部門内での研究、管理、教育の役割において必要な複雑なバランスを強調しています。","コメントは、種子の発見から実装までの研究を管理する際の課題を強調し、産業と学術の連携、特許の独占、資金源、研究者への行政上の負担について懸念があることが示されています。提起された問題には、大学のスタートアップの製薬会社への統合、大学の独立した研究資金の必要性、実践的な学習と産業資金による研究の優先順位が含まれています。共同研究における権利の争いや新興技術の実用的な応用の限られた普及に関する論争も指摘されています。コメントは、大学セクター内での研究、管理、教育の役割において必要とされる複雑なバランスを強調しています。"],"Participants highlighted the importance of forming an economic community and the role of relationships in defining oneself. They referenced Sartre's quote \"Hell is other people\" to underscore the significance of interpersonal connections. The concept of \"Comoning\" was discussed as a relationship-oriented and practical approach. The discussion also touched on DAOs as ecosystems coordinating human actions around protocols. Emphasizing the need for communication and negotiation in forming commons, the dialogue stressed the inadequacy of laws alone in societal contexts and the importance of collaborative spaces for exchanging diverse perspectives on public issues.":["参加者は、経済共同体の形成の重要性と、自己を定義する際の関係の役割を強調しました。彼らは、サルトルの言葉「地獄は他人だ」を引用して、人間関係の重要性を強調しました。関係志向の実践的なアプローチとして、「コモニング」という概念が議論されました。議論では、DAOをプロトコルを中心に人間の行動を調整するエコシステムとして取り上げました。コモンズの形成においてコミュニケーションと交渉の必要性を強調し、法律だけでは社会的文脈で不十分であり、公共問題に対する多様な視点を交換するための協力的な空間の重要性を強調しました。","参加者は、経済共同体の形成の重要性と、自己を定義する際の関係の役割を強調しました。彼らは、サルトルの言葉「地獄は他人だ」を引用して、人間関係の重要性を強調しました。関係志向の実践的なアプローチとして、「コモニング」という概念が議論されました。議論では、DAO（分散自治組織）がプロトコルを中心に人間の行動を調整する生態系として触れられました。共同体の形成におけるコミュニケーションと交渉の必要性を強調し、社会的文脈において法律だけでは不十分であり、公共問題に対する多様な視点を交換するための協力的な空間の重要性が強調されました。"],"Universities serve as common spaces for collaboration, knowledge dissemination, and societal integration, with a focus on liberal arts, research, and education. They are evolving to meet the demands of a knowledge-based society, emphasizing cooperation between students and teachers. The historical context of universities transitioning from medieval knowledge centers to modern multifunctional institutions is highlighted, showcasing their role in national culture and modernization efforts. The importance of universities in promoting arts and sciences integration, facilitating learning through seminars and laboratories, and contributing to societal expectations and national interests is underscored.":["大学は協力、知識の普及、社会統合のための共通の場として機能し、リベラルアーツ、研究、教育に焦点を当てています。知識ベースの社会の要求に応えるために進化し、学生と教師の間の協力を強調しています。中世の知識の中心地から現代の多機能施設への移行する大学の歴史的文脈が強調され、国家文化と近代化の取り組みにおける役割が示されています。大学の重要性は、芸術と科学の統合を促進し、セミナーや実験室を通じた学習を支援し、社会の期待と国家の利益に貢献していることが強調されています。","大学は、協力、知識の普及、社会の統合のための共通の場として機能し、リベラルアーツ、研究、教育に焦点を当てています。彼らは知識ベースの社会の要求に応えるために進化しており、学生と教師の間の協力を強調しています。大学が中世の知識の中心地から現代の多機能な機関に移行する歴史的文脈が強調され、彼らの国家文化と近代化の取り組みにおける役割が示されています。大学の重要性は、芸術と科学の統合を促進し、セミナーや実験室を通じた学習を支援し、社会の期待と国家の利益に貢献していることが強調されています。"],"International student connections with companies, campus appeal, meaningful campus life, post-graduation prospects, and the importance of diverse courses and experiences were highlighted. The role of professors as role models, the value of real-world professional experience in teaching, and the impact of university choice on future employment opportunities were also emphasized. Additionally, the significance of cross-cultural knowledge exchange, the impact of personal opinions in coursework, and the influence of diverse academic experiences on career decisions were noted.":["企業との国際学生のつながり、キャンパスの魅力、意義あるキャンパスライフ、卒業後の見通し、多様なコースや経験の重要性が強調されました。教授の役割モデルとしての役割、実践的な職業経験の価値、大学選択の将来の雇用機会への影響も強調されました。さらに、異文化間の知識交換の重要性、授業における個人の意見の影響、多様な学術的経験がキャリアの決定に与える影響が指摘されました。","企業との国際学生のつながり、キャンパスの魅力、意義あるキャンパスライフ、卒業後の見通し、多様なコースや経験の重要性が強調されました。教授の役割モデルとしての役割、実践的な職業経験の価値、大学選択が将来の雇用機会に与える影響も強調されました。さらに、異文化間の知識交換の重要性、授業における個人の意見の影響、多様な学術的経験がキャリアの決定に与える影響が指摘されました。"],"The comments touch on the importance of establishing university startups, considering mergers of private universities, the evolution of the university system through historical events, the integration of research and education in the Humboldtian university concept, and the trend of students choosing majors based on future job prospects. Additionally, there is a mention of PBL education, early internships, and the balance between enjoying campus life and focusing on future employment.":["コメントは、大学スタートアップの設立の重要性、私立大学の合併の検討、歴史的な出来事を通じた大学制度の進化、フンボルト大学概念における研究と教育の統合、将来の職業展望に基づいた専攻を選択する学生の傾向に触れています。さらに、PBL教育、早期インターンシップ、キャンパスライフを楽しむことと将来の雇用に焦点を当てることのバランスに言及されています。","コメントは、大学スタートアップの設立の重要性、私立大学の合併の検討、歴史的な出来事を通じた大学制度の進化、フンボルト大学概念における研究と教育の統合、将来の仕事の見通しに基づいた専攻を選択する学生の傾向に触れています。さらに、PBL教育、早期インターンシップ、キャンパスライフを楽しむことと将来の雇用に焦点を当てることのバランスに言及されています。"],"The comments touch on the complexities of technical guidance and research contracts, the importance of abiding by rules autonomously, the limitations of laws in addressing demand-specific solutions, the value of acquiring up-to-date knowledge for societal contributions, the necessity of balancing work to sustain life, the pressure on professionals to deliver results within limited timeframes, and the need to consider new admission criteria. Additionally, they highlight the pragmatic nature of actions driven by resume-building, the sense of financial and emotional scarcity, the urgency felt to avoid complacency, the tendency to prioritize high-paying companies as professionals, and the potential for research-focused efforts to significantly increase research budgets.":["コメントは、技術ガイダンスと研究契約の複雑さ、自律的に規則を守る重要性、需要に特化した解決策を扱う法律の限界、社会貢献のための最新知識の習得の価値、生活を維持するための仕事のバランスの必要性、専門家が限られた時間枠内で結果を提供するためのプレッシャー、新しい入学基準を考慮する必要性に触れています。さらに、履歴書作成によって促される行動の実用的な性質、財政的および感情的な不足感、怠惰を避けるために感じる緊急性、専門家として高収入企業を優先する傾向、および研究に焦点を当てた取り組みが研究予算を大幅に増やす可能性について強調しています。","コメントは、技術ガイダンスと研究契約の複雑さ、自律的に規則を守る重要性、需要に特化した解決策を扱う法律の限界、社会貢献のための最新知識の習得の価値、生活を維持するための仕事のバランスの必要性、専門家が限られた時間枠内で結果を提供するためのプレッシャー、新しい入学基準を考慮する必要性に触れています。さらに、履歴書作成によって促される行動の実用的な性質、財政的および感情的な不足感、怠惰を避けるために感じる緊急性、専門家として高収入企業を優先する傾向、研究に焦点を当てた取り組みが研究予算を大幅に増やす可能性に焦点を当てています。"],"The comments touch on various aspects of higher education, highlighting disparities in cultural and lifestyle differences, financial challenges, pressure from academic scholarships, and the impact of online interactions on social connections. Concerns about the practicality of higher education for the impoverished, challenges in financial support transparency, and the shift towards online learning during the pandemic are also discussed. The need for a balance between academic performance and practical skills, as well as the impact of societal expectations on educational choices, is evident throughout the comments.":["コメントは、高等教育のさまざまな側面に触れ、文化的およびライフスタイルの違い、財政的な課題、学術奨学金からのプレッシャー、オンラインの相互作用が社会的つながりに与える影響を強調しています。貧困層にとっての高等教育の実用性、財政支援の透明性における課題、パンデミック中のオンライン学習への移行についても議論されています。学術成績と実践的なスキルのバランスの必要性、教育の選択に対する社会的期待の影響が、コメント全体を通じて明らかになっています。","コメントは、高等教育のさまざまな側面に触れ、文化的およびライフスタイルの違い、財政的な課題、学術奨学金からのプレッシャー、オンラインの相互作用が社会的つながりに与える影響を強調しています。貧困層にとっての高等教育の実用性、財政支援の透明性における課題、パンデミック中のオンライン学習への移行についても議論されています。学術成績と実践的なスキルのバランスの必要性、教育の選択に対する社会的期待の影響が、コメント全体を通じて明らかになっています。"],"The comments touch on the influence of parental education on children's academic success, the importance of respect and support in education, the shift of power in Web3 technology, the value of diverse engagement methods, and the benefits of interdisciplinary expertise. They also highlight the significance of self-reflection, continuous learning, and the inseparable connection between learning and personal growth. Additionally, the comments suggest the potential for unconventional activities like ikebana to provide relief and purpose, and raise the question of whether pursuing personal interests in adulthood can enhance happiness.":["親の教育が子供の学業の成功に与える影響、教育における尊敬とサポートの重要性、Web3テクノロジーにおける権力の移行、多様な関与方法の価値、学際的専門知識の利点に触れています。また、自己反省、継続的学習、学びと個人成長との切り離せない関係の重要性を強調しています。さらに、いけばなのような非伝統的な活動が安心と目的を提供する可能性を示唆し、大人になってからの個人の興味を追求することが幸福を高めるかどうかという問題を提起しています。","親の教育が子供の学業の成功に与える影響、教育における尊敬とサポートの重要性、Web3テクノロジーにおける権力の移行、多様な関与方法の価値、学際的専門知識の利点に触れています。また、自己反省、継続的学習、学びと個人成長との切り離せない関係の重要性を強調しています。さらに、いけばなのような非伝統的な活動が安心と目的を提供する可能性を示唆し、大人になってからの個人の興味を追求することが幸福を高める可能性について問いかけています。"],"The research findings indicate a complex landscape for universities, with challenges in research-industry collaborations, evolving social engagement, and the changing roles of universities. Future trends may involve a greater emphasis on practical learning, industry-funded research, and societal integration. Universities will need to navigate issues such as managing patent monopolies, fostering diverse academic experiences, and adapting to the demands of a knowledge-based society. Embracing interdisciplinary expertise, promoting collaborative spaces, and balancing academic performance with practical skills will be crucial for universities to thrive in the evolving higher education landscape.":["研究結果は、大学にとって複雑な環境を示しており、研究と産業の連携、進化する社会的関与、大学の変化する役割に課題があります。将来のトレンドは、実践的な学び、産業資金による研究、社会との統合に重点を置く可能性があります。大学は特許独占の管理、多様な学術体験の育成、知識ベースの社会の要求への適応などの問題を乗り越える必要があります。学際的な専門知識を取り入れ、協力的なスペースを促進し、学術的なパフォーマンスと実践的なスキルのバランスを取ることが、大学が進化する高等教育環境で繁栄するために不可欠です。","研究結果は、大学にとって複雑な環境を示しており、研究と産業の連携、進化する社会的関与、大学の変化する役割に課題があることを示しています。将来のトレンドは、実践的な学び、産業資金による研究、社会との統合に重点を置く可能性があります。大学は特許独占の管理、多様な学術体験の育成、知識ベースの社会の要求への適応などの問題を乗り越える必要があります。学際的な専門知識を取り入れ、協力的なスペースを促進し、学術的成績と実践的なスキルのバランスを取ることが、大学が進化する高等教育環境で繁栄するために不可欠です。"],"This AI-generated report relies on data from Mizuki Yoshie's research.":["このAI生成レポートは、水木佳枝の研究データに依存しています。","このAI生成レポートは、美月佳枝の研究データに依存しています。"]},"overview":"The research findings indicate a complex landscape for universities, with challenges in research-industry collaborations, evolving social engagement, and the changing roles of universities. Future trends may involve a greater emphasis on practical learning, industry-funded research, and societal integration. Universities will need to navigate issues such as managing patent monopolies, fostering diverse academic experiences, and adapting to the demands of a knowledge-based society. Embracing interdisciplinary expertise, promoting collaborative spaces, and balancing academic performance with practical skills will be crucial for universities to thrive in the evolving higher education landscape.","config":{"name":"Hiromi Ouchi KJ Method","question":"How has the role of universities changed over the past decades, and what trends will shape their future?","input":"KJ法","model":"gpt-3.5-turbo","extraction":{"limit":103,"workers":1,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []\n","prompt":"/system\n\nYou are a professional research assistant and your job is to help \nme prepare a nice and clean datasets of arguments. \n\nThe context is that I have gathered a long list of comments from various media sources and interviews about universities. I want you to help me identify the main ideas and trends related to the future of universities. Your task is to analyze these comments and provide clear, concise summaries of the key themes and trends that emerge from the data. Focus on making the summaries easy to read and insightful, highlighting any recurring patterns or important insights.\nWhen really necessary, you can also break it down into two separate arguments, but it will often be best to return a single arguments. \n\nPlease return the result as a well-formatted JSON list of strings. \n\n/human\n\nAI technologies should be developed with a focus on reducing their own \nenvironmental impact over their lifecycle.\n\n/ai \n\n[\n\"We should focus on reducing the environmental impact of AI technologies\"\n]\n\n/human \n\nThere should be a concerted effort to educate the public about the \ncapabilities, limitations, and ethical considerations of AI.\n\n/ai \n\n[\n\"We should educate the public about the capabilities of AI\",\n\"We should educate the public about the limitations and ethical considerations of AI\"\n]\n\n/human \n\nAI can optimize smart homes and buildings for energy efficiency and occupant wellbeing.\n\n/ ai \n\n[\n\"AI can optimize smart homes and buildings for energy efficiency and occupant wellbeing.\"\n]\n\n/human \n\nAI can help optimize energy grids, reducing waste and carbon emissions.\n\n/ai \n\n[\n\"AI could optimize energy grids to reduce waste and carbon emissions.\"\n]","model":"gpt-3.5-turbo"},"clustering":{"clusters":8,"source_code":"\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom importlib import import_module\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # (!) we import the following modules dynamically for a reason\n    # (they are slow to load and not required for all pipelines)\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    stopwords = import_module('nltk.corpus').stopwords\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module(\n        'sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    stop = stopwords.words(\"english\")\n    vectorizer_model = CountVectorizer(stop_words=stop)\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # Fit the topic model.\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,  # Use the modified n_neighbors\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"},"translation":{"model":"gpt-4","languages":["English","Japanese"],"flags":["EN","JP"],"source_code":"\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages\nfrom langchain.schema import AIMessage\nimport pandas as pd\nimport json\nfrom tqdm import tqdm\n\n\ndef translation(config):\n\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # creating an empty file any, to reduce special casing later\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    UI_copy = [\"Argument\", \"Original comment\", \"Representative arguments\",\n               \"Open full-screen map\", \"Back to report\", \"Hide labels\", \"Show labels\",\n               \"Show filters\", \"Hide filters\", \"Min. votes\", \"Consensus\",\n               \"Showing\", \"arguments\", \"Reset zoom\", \"Click anywhere on the map to close this\",\n               \"Click on the dot for details\",\n               \"agree\", \"disagree\", \"Language\", \"English\", \"arguments\", \"of total\",\n               \"Overview\", \"Cluster analysis\", \"Representative comments\", \"Introduction\",\n               \"Clusters\", \"Appendix\", \"This report was generated using an AI pipeline that consists of the following steps\",\n               \"Step\", \"extraction\", \"show code\", \"hide code\", \"show prompt\", \"hide prompt\", \"embedding\",\n               \"clustering\", \"labelling\", \"takeaways\", \"overview\"]\n\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # handling long takeaways differently, WITHOUT batching too much\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i < len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) > 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e\n","prompt":"/system \n\nYou are a professional translator.\nYou will receive a list of words and sentences written in English. \nPlease return the same list, in the same order, but translated to Japanese.\nMake sure to return a valid JSON list of string of the same length as the original list."},"intro":"This AI-generated report relies on data from Mizuki Yoshie's research.","output_dir":"KJ法","previous":{"name":"Hiromi Ouchi KJ Method","question":"How has the role of universities changed over the past decades, and what trends will shape their future?","input":"KJ法","model":"gpt-3.5-turbo","extraction":{"limit":103,"workers":1,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []\n","prompt":"/system\n\nYou are a professional research assistant and your job is to help \nme prepare a nice and clean datasets of arguments. \n\nThe context is that I have gathered a long list of comments from various media sources and interviews about universities. I want you to help me identify the main ideas and trends related to the future of universities. Your task is to analyze these comments and provide clear, concise summaries of the key themes and trends that emerge from the data. Focus on making the summaries easy to read and insightful, highlighting any recurring patterns or important insights.\nWhen really necessary, you can also break it down into two separate arguments, but it will often be best to return a single arguments. \n\nPlease return the result as a well-formatted JSON list of strings. \n\n/human\n\nAI technologies should be developed with a focus on reducing their own \nenvironmental impact over their lifecycle.\n\n/ai \n\n[\n\"We should focus on reducing the environmental impact of AI technologies\"\n]\n\n/human \n\nThere should be a concerted effort to educate the public about the \ncapabilities, limitations, and ethical considerations of AI.\n\n/ai \n\n[\n\"We should educate the public about the capabilities of AI\",\n\"We should educate the public about the limitations and ethical considerations of AI\"\n]\n\n/human \n\nAI can optimize smart homes and buildings for energy efficiency and occupant wellbeing.\n\n/ ai \n\n[\n\"AI can optimize smart homes and buildings for energy efficiency and occupant wellbeing.\"\n]\n\n/human \n\nAI can help optimize energy grids, reducing waste and carbon emissions.\n\n/ai \n\n[\n\"AI could optimize energy grids to reduce waste and carbon emissions.\"\n]","model":"gpt-3.5-turbo"},"clustering":{"clusters":8,"source_code":"\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom importlib import import_module\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # (!) we import the following modules dynamically for a reason\n    # (they are slow to load and not required for all pipelines)\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    stopwords = import_module('nltk.corpus').stopwords\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module(\n        'sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    stop = stopwords.words(\"english\")\n    vectorizer_model = CountVectorizer(stop_words=stop)\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # Fit the topic model.\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,  # Use the modified n_neighbors\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"},"translation":{"model":"gpt-4","languages":["English","Japanese"],"flags":["EN","JP"],"source_code":"\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages\nfrom langchain.schema import AIMessage\nimport pandas as pd\nimport json\nfrom tqdm import tqdm\n\n\ndef translation(config):\n\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # creating an empty file any, to reduce special casing later\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    UI_copy = [\"Argument\", \"Original comment\", \"Representative arguments\",\n               \"Open full-screen map\", \"Back to report\", \"Hide labels\", \"Show labels\",\n               \"Show filters\", \"Hide filters\", \"Min. votes\", \"Consensus\",\n               \"Showing\", \"arguments\", \"Reset zoom\", \"Click anywhere on the map to close this\",\n               \"Click on the dot for details\",\n               \"agree\", \"disagree\", \"Language\", \"English\", \"arguments\", \"of total\",\n               \"Overview\", \"Cluster analysis\", \"Representative comments\", \"Introduction\",\n               \"Clusters\", \"Appendix\", \"This report was generated using an AI pipeline that consists of the following steps\",\n               \"Step\", \"extraction\", \"show code\", \"hide code\", \"show prompt\", \"hide prompt\", \"embedding\",\n               \"clustering\", \"labelling\", \"takeaways\", \"overview\"]\n\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # handling long takeaways differently, WITHOUT batching too much\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i < len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) > 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e\n","prompt":"/system \n\nYou are a professional translator.\nYou will receive a list of words and sentences written in English. \nPlease return the same list, in the same order, but translated to Japanese.\nMake sure to return a valid JSON list of string of the same length as the original list."},"intro":"This AI-generated report relies on data from Mizuki Yoshie's research.","output_dir":"KJ法","embedding":{"source_code":"\nfrom langchain_openai import OpenAIEmbeddings, ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nYou are a category labeling assistant that generates a category label \nfor a set of arguments within a broader consultation. You are given the main question \nof the consultation, list of arguments inside the cluster, and a list of arguments \noutside this cluster. You answer with a single category label that summarizes the \ncluster. \n\nYou do not include context that is already obvious from the question (for example: \nif the question of the consultation is something like \"what challenges are you facing \nin France\", there is no need to repeat \"in France\" in the cluster label).\n\nThe label must be very concise and just precise enough to capture what distinguishes \nthe cluster from the arguments found outside. \n\n/human\n\nQuestion of the consultation: \"What do you think has been the impact of the UK decision to leave the EU?\"\n\nExamples of arguments OUTSIDE the cluster of interest:\n\n * We faced limitations in educational and cultural exchange opportunities due to exclusion from the Erasmus program.\n * The UK dealt with longer travel times caused by increased border checks, affecting commuters and vacationers.\n * We saw reduced cooperation in environmental standards, hindering efforts to combat climate change.\n * I experienced challenges in patient care due to disruptions in reciprocal healthcare agreements.\n * We faced complexity in residency and citizenship applications for families due to Brexit-related changes.\n * The UK witnessed hindrance in global efforts to address research challenges due to reduced collaboration opportunities.\n * We faced limitations in creative projects due to exclusion from EU cultural funding programs.\n * The UK witnessed setbacks in charitable initiatives and community support due to the loss of EU funding.\n * We experienced challenges in cross-border dispute resolution due to weakened consumer protections.\n * The UK faced limitations in touring EU countries as professional musicians, impacting careers.\n\nExamples of arguments inside the cluster:\n\n * We experienced supply chain disruptions due to Brexit, leading to increased costs and delayed deliveries for businesses.\n * I faced market fluctuations and uncertainties in investments and retirement savings because of Brexit.\n * The UK dealt with reduced profit margins as an exporter due to new tariffs and customs procedures.\n * We lost jobs because companies relocated operations to stay within the EU market post-Brexit.\n * The UK struggled with the increased cost of living caused by skyrocketing prices of imported goods.\n * We witnessed a decline in investment in the UK tech sector, impacting innovation and job opportunities.\n * The UK saw a decline in tourism due to new visa regulations, affecting hospitality businesses.\n * I experienced reduced purchasing power and increased travel expenses due to the drop in the pound's value.\n\n/ai \n\nNegative Financial Impact\n","model":"gpt-3.5-turbo"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nYou are an expert research assistant working in a think tank. You will be given a list of comments from various media sources and interviews about universities. You respond with one or two paragraphs summarizing your main takeaways. You are very concise and write short, snappy sentences which are easy to read. \n\n/human\n\n[\n\"I firmly believe that gun violence constitutes a severe public health crisis in our society.\",\n\"We need to address this issue urgently through comprehensive gun control measures.\", \n\"I support the implementation of universal background checks for all gun buyers\",\n\"I am in favor of banning assault weapons and high-capacity magazines.\",\n\"I advocate for stricter regulations to prevent illegal gun trafficking.\",\n\"Mental health evaluations should be a mandatory part of the gun purchasing process.\"\n]\n\n/ai \n\nParticipants called for comprehensive gun control, emphasizing universal background checks, assault weapon bans, curbing illegal gun trafficking, and prioritizing mental health evaluations.","model":"gpt-3.5-turbo"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n","prompt":"/system \n\nYou are an expert research assistant working in a think tank. \nYour team has run a public consultation on a given topic and has \nstarted to analyze what the different cluster of options are. \nYou will now receive the list of clusters with a brief \nanalysis of each cluster. Your job is to return a short summary of what \nthe findings were. Your summary must be very concise (at most one \nparagraph, containing at most four sentences) and you must avoid platitudes. ","model":"gpt-3.5-turbo"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"translations\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) > 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":true,"reason":"some parameters changed: limit"},{"step":"embedding","run":true,"reason":"some dependent steps will re-run: extraction"},{"step":"clustering","run":true,"reason":"some dependent steps will re-run: embedding"},{"step":"labelling","run":true,"reason":"some dependent steps will re-run: clustering"},{"step":"takeaways","run":true,"reason":"some dependent steps will re-run: clustering"},{"step":"overview","run":true,"reason":"some dependent steps will re-run: labelling, takeaways"},{"step":"translation","run":true,"reason":"some dependent steps will re-run: extraction, labelling, takeaways, overview"},{"step":"aggregation","run":true,"reason":"some dependent steps will re-run: extraction, clustering, labelling, takeaways, overview, translation"},{"step":"visualization","run":true,"reason":"some dependent steps will re-run: aggregation"}],"status":"completed","start_time":"2024-09-10T17:09:01.086946","completed_jobs":[{"step":"extraction","completed":"2024-09-10T17:11:29.663338","duration":148.569691,"params":{"limit":103,"workers":1,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []\n","prompt":"/system\n\nYou are a professional research assistant and your job is to help \nme prepare a nice and clean datasets of arguments. \n\nThe context is that I have gathered a long list of comments from various media sources and interviews about universities. I want you to help me identify the main ideas and trends related to the future of universities. Your task is to analyze these comments and provide clear, concise summaries of the key themes and trends that emerge from the data. Focus on making the summaries easy to read and insightful, highlighting any recurring patterns or important insights.\nWhen really necessary, you can also break it down into two separate arguments, but it will often be best to return a single arguments. \n\nPlease return the result as a well-formatted JSON list of strings. \n\n/human\n\nAI technologies should be developed with a focus on reducing their own \nenvironmental impact over their lifecycle.\n\n/ai \n\n[\n\"We should focus on reducing the environmental impact of AI technologies\"\n]\n\n/human \n\nThere should be a concerted effort to educate the public about the \ncapabilities, limitations, and ethical considerations of AI.\n\n/ai \n\n[\n\"We should educate the public about the capabilities of AI\",\n\"We should educate the public about the limitations and ethical considerations of AI\"\n]\n\n/human \n\nAI can optimize smart homes and buildings for energy efficiency and occupant wellbeing.\n\n/ ai \n\n[\n\"AI can optimize smart homes and buildings for energy efficiency and occupant wellbeing.\"\n]\n\n/human \n\nAI can help optimize energy grids, reducing waste and carbon emissions.\n\n/ai \n\n[\n\"AI could optimize energy grids to reduce waste and carbon emissions.\"\n]","model":"gpt-3.5-turbo"}},{"step":"embedding","completed":"2024-09-10T17:11:31.788397","duration":2.122474,"params":{"source_code":"\nfrom langchain_openai import OpenAIEmbeddings, ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"}},{"step":"clustering","completed":"2024-09-10T17:11:56.444676","duration":24.653963,"params":{"clusters":8,"source_code":"\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom importlib import import_module\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # (!) we import the following modules dynamically for a reason\n    # (they are slow to load and not required for all pipelines)\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    stopwords = import_module('nltk.corpus').stopwords\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module(\n        'sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    stop = stopwords.words(\"english\")\n    vectorizer_model = CountVectorizer(stop_words=stop)\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # Fit the topic model.\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,  # Use the modified n_neighbors\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result"}},{"step":"labelling","completed":"2024-09-10T17:12:02.567909","duration":6.120389,"params":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nYou are a category labeling assistant that generates a category label \nfor a set of arguments within a broader consultation. You are given the main question \nof the consultation, list of arguments inside the cluster, and a list of arguments \noutside this cluster. You answer with a single category label that summarizes the \ncluster. \n\nYou do not include context that is already obvious from the question (for example: \nif the question of the consultation is something like \"what challenges are you facing \nin France\", there is no need to repeat \"in France\" in the cluster label).\n\nThe label must be very concise and just precise enough to capture what distinguishes \nthe cluster from the arguments found outside. \n\n/human\n\nQuestion of the consultation: \"What do you think has been the impact of the UK decision to leave the EU?\"\n\nExamples of arguments OUTSIDE the cluster of interest:\n\n * We faced limitations in educational and cultural exchange opportunities due to exclusion from the Erasmus program.\n * The UK dealt with longer travel times caused by increased border checks, affecting commuters and vacationers.\n * We saw reduced cooperation in environmental standards, hindering efforts to combat climate change.\n * I experienced challenges in patient care due to disruptions in reciprocal healthcare agreements.\n * We faced complexity in residency and citizenship applications for families due to Brexit-related changes.\n * The UK witnessed hindrance in global efforts to address research challenges due to reduced collaboration opportunities.\n * We faced limitations in creative projects due to exclusion from EU cultural funding programs.\n * The UK witnessed setbacks in charitable initiatives and community support due to the loss of EU funding.\n * We experienced challenges in cross-border dispute resolution due to weakened consumer protections.\n * The UK faced limitations in touring EU countries as professional musicians, impacting careers.\n\nExamples of arguments inside the cluster:\n\n * We experienced supply chain disruptions due to Brexit, leading to increased costs and delayed deliveries for businesses.\n * I faced market fluctuations and uncertainties in investments and retirement savings because of Brexit.\n * The UK dealt with reduced profit margins as an exporter due to new tariffs and customs procedures.\n * We lost jobs because companies relocated operations to stay within the EU market post-Brexit.\n * The UK struggled with the increased cost of living caused by skyrocketing prices of imported goods.\n * We witnessed a decline in investment in the UK tech sector, impacting innovation and job opportunities.\n * The UK saw a decline in tourism due to new visa regulations, affecting hospitality businesses.\n * I experienced reduced purchasing power and increased travel expenses due to the drop in the pound's value.\n\n/ai \n\nNegative Financial Impact\n","model":"gpt-3.5-turbo"}},{"step":"takeaways","completed":"2024-09-10T17:12:20.651433","duration":18.080703,"params":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nYou are an expert research assistant working in a think tank. You will be given a list of comments from various media sources and interviews about universities. You respond with one or two paragraphs summarizing your main takeaways. You are very concise and write short, snappy sentences which are easy to read. \n\n/human\n\n[\n\"I firmly believe that gun violence constitutes a severe public health crisis in our society.\",\n\"We need to address this issue urgently through comprehensive gun control measures.\", \n\"I support the implementation of universal background checks for all gun buyers\",\n\"I am in favor of banning assault weapons and high-capacity magazines.\",\n\"I advocate for stricter regulations to prevent illegal gun trafficking.\",\n\"Mental health evaluations should be a mandatory part of the gun purchasing process.\"\n]\n\n/ai \n\nParticipants called for comprehensive gun control, emphasizing universal background checks, assault weapon bans, curbing illegal gun trafficking, and prioritizing mental health evaluations.","model":"gpt-3.5-turbo"}},{"step":"overview","completed":"2024-09-10T17:12:22.479060","duration":1.823712,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n","prompt":"/system \n\nYou are an expert research assistant working in a think tank. \nYour team has run a public consultation on a given topic and has \nstarted to analyze what the different cluster of options are. \nYou will now receive the list of clusters with a brief \nanalysis of each cluster. Your job is to return a short summary of what \nthe findings were. Your summary must be very concise (at most one \nparagraph, containing at most four sentences) and you must avoid platitudes. ","model":"gpt-3.5-turbo"}},{"step":"translation","completed":"2024-09-10T17:21:28.726236","duration":546.241614,"params":{"model":"gpt-4","languages":["English","Japanese"],"flags":["EN","JP"],"source_code":"\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages\nfrom langchain.schema import AIMessage\nimport pandas as pd\nimport json\nfrom tqdm import tqdm\n\n\ndef translation(config):\n\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # creating an empty file any, to reduce special casing later\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    UI_copy = [\"Argument\", \"Original comment\", \"Representative arguments\",\n               \"Open full-screen map\", \"Back to report\", \"Hide labels\", \"Show labels\",\n               \"Show filters\", \"Hide filters\", \"Min. votes\", \"Consensus\",\n               \"Showing\", \"arguments\", \"Reset zoom\", \"Click anywhere on the map to close this\",\n               \"Click on the dot for details\",\n               \"agree\", \"disagree\", \"Language\", \"English\", \"arguments\", \"of total\",\n               \"Overview\", \"Cluster analysis\", \"Representative comments\", \"Introduction\",\n               \"Clusters\", \"Appendix\", \"This report was generated using an AI pipeline that consists of the following steps\",\n               \"Step\", \"extraction\", \"show code\", \"hide code\", \"show prompt\", \"hide prompt\", \"embedding\",\n               \"clustering\", \"labelling\", \"takeaways\", \"overview\"]\n\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # handling long takeaways differently, WITHOUT batching too much\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i < len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) > 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e\n","prompt":"/system \n\nYou are a professional translator.\nYou will receive a list of words and sentences written in English. \nPlease return the same list, in the same order, but translated to Japanese.\nMake sure to return a valid JSON list of string of the same length as the original list."}},{"step":"aggregation","completed":"2024-09-10T17:21:28.858330","duration":0.128842,"params":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"translations\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) > 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"}},{"step":"visualization","completed":"2024-09-10T17:21:47.091059","duration":18.231203,"params":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"}}],"lock_until":"2024-09-10T17:26:47.093667","current_job":"visualization","current_job_started":"2024-09-10T17:21:28.859887","translation_prompt":"/system \n\nYou are a professional translator.\nYou will receive a list of words and sentences written in English. \nPlease return the same list, in the same order, but translated to Japanese.\nMake sure to return a valid JSON list of string of the same length as the original list.","previously_completed_jobs":[],"end_time":"2024-09-10T17:21:47.093649"},"embedding":{"source_code":"\nfrom langchain_openai import OpenAIEmbeddings, ChatOpenAI\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nYou are a category labeling assistant that generates a category label \nfor a set of arguments within a broader consultation. You are given the main question \nof the consultation, list of arguments inside the cluster, and a list of arguments \noutside this cluster. You answer with a single category label that summarizes the \ncluster. \n\nYou do not include context that is already obvious from the question (for example: \nif the question of the consultation is something like \"what challenges are you facing \nin France\", there is no need to repeat \"in France\" in the cluster label).\n\nThe label must be very concise and just precise enough to capture what distinguishes \nthe cluster from the arguments found outside. \n\n/human\n\nQuestion of the consultation: \"What do you think has been the impact of the UK decision to leave the EU?\"\n\nExamples of arguments OUTSIDE the cluster of interest:\n\n * We faced limitations in educational and cultural exchange opportunities due to exclusion from the Erasmus program.\n * The UK dealt with longer travel times caused by increased border checks, affecting commuters and vacationers.\n * We saw reduced cooperation in environmental standards, hindering efforts to combat climate change.\n * I experienced challenges in patient care due to disruptions in reciprocal healthcare agreements.\n * We faced complexity in residency and citizenship applications for families due to Brexit-related changes.\n * The UK witnessed hindrance in global efforts to address research challenges due to reduced collaboration opportunities.\n * We faced limitations in creative projects due to exclusion from EU cultural funding programs.\n * The UK witnessed setbacks in charitable initiatives and community support due to the loss of EU funding.\n * We experienced challenges in cross-border dispute resolution due to weakened consumer protections.\n * The UK faced limitations in touring EU countries as professional musicians, impacting careers.\n\nExamples of arguments inside the cluster:\n\n * We experienced supply chain disruptions due to Brexit, leading to increased costs and delayed deliveries for businesses.\n * I faced market fluctuations and uncertainties in investments and retirement savings because of Brexit.\n * The UK dealt with reduced profit margins as an exporter due to new tariffs and customs procedures.\n * We lost jobs because companies relocated operations to stay within the EU market post-Brexit.\n * The UK struggled with the increased cost of living caused by skyrocketing prices of imported goods.\n * We witnessed a decline in investment in the UK tech sector, impacting innovation and job opportunities.\n * The UK saw a decline in tourism due to new visa regulations, affecting hospitality businesses.\n * I experienced reduced purchasing power and increased travel expenses due to the drop in the pound's value.\n\n/ai \n\nNegative Financial Impact\n","model":"gpt-3.5-turbo"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nYou are an expert research assistant working in a think tank. You will be given a list of comments from various media sources and interviews about universities. You respond with one or two paragraphs summarizing your main takeaways. You are very concise and write short, snappy sentences which are easy to read. \n\n/human\n\n[\n\"I firmly believe that gun violence constitutes a severe public health crisis in our society.\",\n\"We need to address this issue urgently through comprehensive gun control measures.\", \n\"I support the implementation of universal background checks for all gun buyers\",\n\"I am in favor of banning assault weapons and high-capacity magazines.\",\n\"I advocate for stricter regulations to prevent illegal gun trafficking.\",\n\"Mental health evaluations should be a mandatory part of the gun purchasing process.\"\n]\n\n/ai \n\nParticipants called for comprehensive gun control, emphasizing universal background checks, assault weapon bans, curbing illegal gun trafficking, and prioritizing mental health evaluations.","model":"gpt-3.5-turbo"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n","prompt":"/system\nYou are an expert research assistant working in a think tank.\nYour team has conducted research on a given topic and has\nstarted to analyze the different clusters of options.\nYou will now receive a list of clusters with a brief\nanalysis of each cluster.\nYour job is to return a short summary of what the findings were. Your summary must be very concise (at most one paragraph, containing at most four sentences) and you must avoid platitudes.\nAdditionally, provide insights into the future of universities based on the data you are analyzing. Highlight any emerging trends, challenges, or opportunities that may shape the future of higher education. Your analysis should offer clear, forward-looking perspectives that are relevant to the evolving landscape of universities.","model":"gpt-3.5-turbo"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"translations\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) > 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":false,"reason":"nothing changed"},{"step":"embedding","run":false,"reason":"nothing changed"},{"step":"clustering","run":false,"reason":"nothing changed"},{"step":"labelling","run":false,"reason":"nothing changed"},{"step":"takeaways","run":false,"reason":"nothing changed"},{"step":"overview","run":true,"reason":"some parameters changed: prompt"},{"step":"translation","run":true,"reason":"some dependent steps will re-run: overview"},{"step":"aggregation","run":true,"reason":"some dependent steps will re-run: overview, translation"},{"step":"visualization","run":true,"reason":"some dependent steps will re-run: aggregation"}],"status":"running","start_time":"2024-09-10T17:32:51.120248","completed_jobs":[{"step":"overview","completed":"2024-09-10T17:32:53.799799","duration":2.674683,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n","prompt":"/system\nYou are an expert research assistant working in a think tank.\nYour team has conducted research on a given topic and has\nstarted to analyze the different clusters of options.\nYou will now receive a list of clusters with a brief\nanalysis of each cluster.\nYour job is to return a short summary of what the findings were. Your summary must be very concise (at most one paragraph, containing at most four sentences) and you must avoid platitudes.\nAdditionally, provide insights into the future of universities based on the data you are analyzing. Highlight any emerging trends, challenges, or opportunities that may shape the future of higher education. Your analysis should offer clear, forward-looking perspectives that are relevant to the evolving landscape of universities.","model":"gpt-3.5-turbo"}},{"step":"translation","completed":"2024-09-10T17:42:56.829509","duration":603.02654,"params":{"model":"gpt-4","languages":["English","Japanese"],"flags":["EN","JP"],"source_code":"\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages\nfrom langchain.schema import AIMessage\nimport pandas as pd\nimport json\nfrom tqdm import tqdm\n\n\ndef translation(config):\n\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # creating an empty file any, to reduce special casing later\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    UI_copy = [\"Argument\", \"Original comment\", \"Representative arguments\",\n               \"Open full-screen map\", \"Back to report\", \"Hide labels\", \"Show labels\",\n               \"Show filters\", \"Hide filters\", \"Min. votes\", \"Consensus\",\n               \"Showing\", \"arguments\", \"Reset zoom\", \"Click anywhere on the map to close this\",\n               \"Click on the dot for details\",\n               \"agree\", \"disagree\", \"Language\", \"English\", \"arguments\", \"of total\",\n               \"Overview\", \"Cluster analysis\", \"Representative comments\", \"Introduction\",\n               \"Clusters\", \"Appendix\", \"This report was generated using an AI pipeline that consists of the following steps\",\n               \"Step\", \"extraction\", \"show code\", \"hide code\", \"show prompt\", \"hide prompt\", \"embedding\",\n               \"clustering\", \"labelling\", \"takeaways\", \"overview\"]\n\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # handling long takeaways differently, WITHOUT batching too much\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i < len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) > 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries > 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e\n","prompt":"/system \n\nYou are a professional translator.\nYou will receive a list of words and sentences written in English. \nPlease return the same list, in the same order, but translated to Japanese.\nMake sure to return a valid JSON list of string of the same length as the original list."}}],"lock_until":"2024-09-10T17:47:56.834638","current_job":"aggregation","current_job_started":"2024-09-10T17:42:56.834610","translation_prompt":"/system \n\nYou are a professional translator.\nYou will receive a list of words and sentences written in English. \nPlease return the same list, in the same order, but translated to Japanese.\nMake sure to return a valid JSON list of string of the same length as the original list."}}},"__N_SSG":true}